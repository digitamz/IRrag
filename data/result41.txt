{'sample_level_eval_list': {'claim_check_methods_0_truth_method_0': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}, 'claim_check_methods_0_truth_method_1': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}}, 'dataset_level_eval_list': {'claim_check_methods_0_truth_method_0': {'prr': np.float64(-0.9585557709559753)}, 'claim_check_methods_0_truth_method_1': {'prr': np.float64(-1.227457294526786)}}, 'output_dict': {'previous_context': [{'role': 'system', 'content': 'You are a helpful assistant. Give precise answers.'}], 'user_prompt': 'Context: {context}\nQuestion: {question}', 'generation': ['Elizabeth Inglis, born Desiree Mary Lucy Hawkins on July 10, 1913, in Colchester, Essex, was an English actress known for her contributions to British cinema in the 1930s and early 1940s. Her parents were Margaret Inglis (née Hunt) and Alan George Hawkins.\n\n### Early Career\n- **Screen Debut**: Inglis made her screen debut in the 1934 film "Borrowed Clothes."\n- **Notable Roles**: She had a small part in Alfred Hitchcock\'s classic "The 39 Steps" (1935) as Hilary Jordan. One of her most recognized roles was playing the young maid Nancy in the original British production of Patrick Hamilton\'s stage thriller "Gas Light."\n\n### Personal Life\n- **Marriage and Family**: After retiring from acting, Inglis married a man named Weaver. The couple had two children, one of whom, Susan, became the renowned actress Sigourney Weaver.\n- **Later Life**: A photograph of Inglis was featured in a deleted scene from the 1986 film "Aliens," where it appeared as Sigourney Weaver\'s character\'s elderly grown daughter, Amanda Ripley.\n\n### Death\n- **Passing**: Elizabeth Inglis died on August 25, 2007, in Santa Barbara, California, at the age of 94.\n\n### Legacy\n- **Acting Contributions**: Her roles in notable films and stage productions have left a lasting impact on British and international cinema.\n- **Family Legacy**: Through her daughter Sigourney Weaver, Elizabeth Inglis\'s legacy continues in the world of film and entertainment.\n\nElizabeth Inglis\'s career, though relatively short, was marked by significant roles that have been remembered and appreciated by film enthusiasts and historians.'], 'claims': [['Elizabeth Inglis was born Desiree Mary Lucy Hawkins on July 10, 1913, in Colchester, Essex.', 'Elizabeth Inglis was an English actress.', 'Elizabeth Inglis was known for her contributions to British cinema in the 1930s and early 1940s.', "Elizabeth Inglis's mother was Margaret Inglis (née Hunt).", "Elizabeth Inglis's father was Alan George Hawkins.", 'Inglis made her screen debut in the 1934 film Borrowed Clothes.', "She had a small part in Alfred Hitchcock's classic 'The 39 Steps' (1935) as Hilary Jordan.", "One of her most recognized roles was playing the young maid Nancy in the original British production of Patrick Hamilton's stage thriller 'Gas Light.'", 'After retiring from acting, Inglis married a man named Weaver.', 'The couple had two children.', 'One of the children, Susan, became the renowned actress Sigourney Weaver.', "A photograph of Inglis was featured in a deleted scene from the 1986 film 'Aliens'.", "In the deleted scene, the photograph of Inglis appeared as Sigourney Weaver's character's elderly grown daughter, Amanda Ripley.", 'Elizabeth Inglis died on August 25, 2007.', 'Elizabeth Inglis died in Santa Barbara, California.', 'Elizabeth Inglis died at the age of 94.', 'Her roles in notable films have left a lasting impact on British and international cinema.', 'Her roles in notable stage productions have left a lasting impact on British and international cinema.', 'Elizabeth Inglis has a daughter named Sigourney Weaver.', "Sigourney Weaver continues Elizabeth Inglis's legacy in the world of film and entertainment.", "Elizabeth Inglis's career was relatively short.", "Elizabeth Inglis's career was marked by significant roles.", "Elizabeth Inglis's roles have been remembered by film enthusiasts.", "Elizabeth Inglis's roles have been appreciated by film historians."]], 'claim_correctness': [array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,
       0, 1])], 'question_text': ['Tell me a bio of Elizabeth Inglis.'], 'context': ['{\n  "id" : "16739326",\n  "contents" : "\\"Elizabeth Inglis\\"\\nElizabeth Inglis Elizabeth Inglis (born Desiree Mary Lucy Hawkins, 10 July 1913 – 25 August 2007), also known as Elizabeth Earl, was an English actress, known for her role in \\"\\"The Letter\\"\\". Inglis was born Desiree Mary Lucy Hawkins in Colchester, Essex, the daughter of Margaret Inglis (née Hunt) and Alan George Hawkins. Her screen debut was in the 1934 film, \\"\\"Borrowed Clothes\\"\\". She then had a small part in \\"\\"The 39 Steps\\"\\" (1935) as Hilary Jordan. She played the role of the young maid Nancy in the original British production of Patrick Hamilton\'s Victorian stage thriller \\"\\"Gas Light\\"\\", which"\n}\n{\n  "id" : "16739328",\n  "contents" : "\\"Elizabeth Inglis\\"\\ntelevision overtook radio as America\'s dominant form of home entertainment. After marrying Weaver, Inglis retired from acting altogether. The couple had two children, one of whom, Susan, became actress Sigourney Weaver. A photograph of Inglis was seen in a deleted scene in \\"\\"Aliens\\"\\" as Weaver\'s character\'s elderly grown daughter, Amanda Ripley. Inglis died on August 25, 2007, in Santa Barbara, California, aged 94. Elizabeth Inglis Elizabeth Inglis (born Desiree Mary Lucy Hawkins, 10 July 1913 – 25 August 2007), also known as Elizabeth Earl, was an English actress, known for her role in \\"\\"The Letter\\"\\". Inglis was born Desiree Mary"\n}\n{\n  "id" : "2670776",\n  "contents" : "\\"Elisabeth Inglis-Jones\\"\\nElisabeth Inglis-Jones Elisabeth Inglis-Jones (1900–1994) was a Welsh novelist and biographer. In 1929, she published \\"\\"Starved Fields\\"\\", the first of six historical novels. She was also an important writer of local history and biography. Her novel \\"\\"Crumbling Pageant\\"\\" was republished in 2015. Born in January 1900 in London, Inglis-Jones was brought up in the village of Derry Ormond, in what is now the county of Ceredigion. She lived on the Derry Ormond Estate, which had been owned by her family since 1783. However, the house was demolished in 1953. Inglis-Jones moved back to the London area around 1937. In her"\n}'], 'claim_check_methods': ['QuestionAnswerGeneration'], 'claim_check_methods_0': {'name': 'Claim Check Method by Generating Questions and Answers.\nQuestion generation model: openrouter/qwen/qwen-2.5-72b-instruct\nNumber of questions to be generated for a stament: 2\nNumber of trials to generate an answer that entails with the claim: 2\nEntailment check model: <class \'transformers.models.deberta.modeling_deberta.DebertaForSequenceClassification\'>\n\nQuestion generation instruction for the first claim:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nQuestion generation instruction for claims with preceeding text:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nAnswer generation instruction:\n    [{\'role\': \'system\', \'content\': \'You are a helpful assistant. Give a single claim answer to given question. Don\\\\‘t provide any additional information. Just answer the question with a brief sentence in a single claim.\'}, {\'role\': \'user\', \'content\': \'{question}\'}]\n\nTruth methods to assign a score the question(s):\n   [<TruthTorchLM.truth_methods.matrix_degree_uncertainty.MatrixDegreeUncertainty object at 0x000001CF401A3F10>, <TruthTorchLM.truth_methods.eccentricity_uncertainty.EccentricityUncertainty object at 0x000001CF401F93F0>]', 'truth_methods': ['MatrixDegreeUncertainty', 'EccentricityUncertainty'], 'truth_methods_name': ['MatrixDegreeUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x000001CF401A3DC0>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'temperature\': 3.0, \'batch_generation\': True}', 'EccentricityUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x000001CF4020A740>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'eigen_threshold\': 0.9, \'temperature\': 3.0, \'batch_generation\': True}'], 'truth_values': [[[np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.5171594524383545), np.float64(-2.884299497010164)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.04875679016113281), np.float64(-3.885780586188048e-16)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.06809853792190551), np.float64(-0.00452978728675002)], [np.float64(-0.05439015626907349), np.float64(-0.0019974744001474143)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.06465249300003052), np.float64(-0.006529065581093951)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.4041289496421814), np.float64(-3.7117866539364606)], [np.float64(-0.09126940965652466), np.float64(-0.019058028244441638)], [np.float64(-0.05023019790649414), np.float64(-0.005588791335816912)]]], 'normalized_truth_values': [[[np.int64(0), np.int64(0)], [np.float64(0.37351668824411005), np.float64(0.05293517475492414)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.4878132165908325), np.float64(0.4999999999999999)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.48298194165532843), np.float64(0.49886755511469566)], [np.float64(0.4864058120623404), np.float64(0.4995006315659991)], [np.int64(0), np.int64(0)], [np.float64(0.483842504477962), np.float64(0.498367739403151)], [np.int64(0), np.int64(0)], [np.float64(0.4003207208375064), np.float64(0.023851056798743924)], [np.float64(0.477198473648107), np.float64(0.4952356371427503)], [np.float64(0.48744509015832016), np.float64(0.49860280580277605)]]]}}}