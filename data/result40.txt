{'sample_level_eval_list': {'claim_check_methods_0_truth_method_0': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}, 'claim_check_methods_0_truth_method_1': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}}, 'dataset_level_eval_list': {'claim_check_methods_0_truth_method_0': {'prr': np.float64(0.5)}, 'claim_check_methods_0_truth_method_1': {'prr': np.float64(0.5)}}, 'output_dict': {'previous_context': [{'role': 'system', 'content': 'You are a helpful assistant. Give precise answers.'}], 'user_prompt': 'Context: {context}\nQuestion: {question}', 'generation': ['Amr Diab (born October 11, 1961) is a renowned Egyptian vocalist, writer, and recording artist. Born in Port Said, Egypt, to an artistic family, Diab\'s father, Abdul Basset Diab, worked for the Suez Canal. Diab\'s musical journey began early, and he earned a bachelor\'s degree in Arabic Music from the Cairo Academy of Arts in 1986.\n\n### Early Career and Education\nDiab released his first album, "Ya Tareeq," in 1983. His second album, "Ghanny Men Albak," was released in 1984 and marked the beginning of a series of successful records with Delta Sound, including "Hala Hala" (1986), "Khalseen" (1987), and "Mayyal" (1988).\n\n### Musical Style and Innovations\nAmr Diab is known for his unique style, which he terms "Mediterranean Music," a blend of Western and Egyptian rhythms. By 1992, he became the first Egyptian and Middle Eastern artist to start making high-tech music videos, further cementing his status as a pioneer in the music industry.\n\n### Personal Life\nDiab is married to Zeina Ashour, who is from Saudi Arabia. They have three children: a son named Abdallah and two daughters, Kinzy and Jana. From his first marriage to the actress Shereen Reda, he has a daughter named Nour.\n\n### Awards and Achievements\nAmr Diab has received numerous accolades throughout his career, including:\n- 6 African Music Awards\n- Big Apple Music Awards 2009 for Lifetime Achievements and Best Singer of the Year\n- The Global Icon Award, Most Popular Artist, and Best Arabic Male Artist in 2014\n- Guinness World Records title for Most World Music Awards for Best Selling Middle Eastern Artist on September 28, 2016\n\n### Legacy\nDiab\'s influence extends beyond Egypt, as he has established himself as an acclaimed recording artist and author in most Mediterranean countries. His innovative approach to music and his significant contributions to the industry have made him a cultural icon, respected both within the Middle East and internationally.'], 'claims': [['Amr Diab was born on October 11, 1961.', 'Amr Diab is a renowned Egyptian vocalist, writer, and recording artist.', 'Amr Diab was born in Port Said, Egypt.', "Amr Diab's father, Abdul Basset Diab, worked for the Suez Canal.", "Amr Diab earned a bachelor's degree in Arabic Music from the Cairo Academy of Arts in 1986.", "Diab released his first album, 'Ya Tareeq,' in 1983.", "Diab's second album, 'Ghanny Men Albak,' was released in 1984.", "Diab's second album, 'Ghanny Men Albak,' marked the beginning of a series of successful records with Delta Sound.", "Diab released the album 'Hala Hala' in 1986.", "Diab released the album 'Khalseen' in 1987.", "Diab released the album 'Mayyal' in 1988.", 'Amr Diab is known for his unique style.', "Amr Diab terms his unique style as 'Mediterranean Music.',", "'Mediterranean Music' is a blend of Western and Egyptian rhythms.", 'By 1992, Amr Diab became the first Egyptian and Middle Eastern artist to start making high-tech music videos.', "Amr Diab's high-tech music videos cemented his status as a pioneer in the music industry.", 'Diab is married to Zeina Ashour.', 'Zeina Ashour is from Saudi Arabia.', 'Diab and Zeina Ashour have three children.', 'Diab and Zeina Ashour have a son named Abdallah.', 'Diab and Zeina Ashour have two daughters named Kinzy and Jana.', 'Diab was previously married to the actress Shereen Reda.', 'Diab has a daughter named Nour from his first marriage to Shereen Reda.', 'Amr Diab has received numerous accolades throughout his career.', '6 African Music Awards have been given.', 'Big Apple Music Awards 2009 were given for Lifetime Achievements.', 'Big Apple Music Awards 2009 were given for Best Singer of the Year.', 'The Global Icon Award was received in 2014.', 'The Most Popular Artist award was received in 2014.', 'The Best Arabic Male Artist award was received in 2014.', 'Amr Diab won the Guinness World Records title for Most World Music Awards for Best Selling Middle Eastern Artist on September 28, 2016.', "Diab's influence extends beyond Egypt.", 'Diab has established himself as an acclaimed recording artist and author in most Mediterranean countries.', 'Diab has an innovative approach to music.', 'Diab has made significant contributions to the music industry.', 'Diab is a cultural icon.', 'Diab is respected within the Middle East.', 'Diab is respected internationally.']], 'claim_correctness': [array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])], 'question_text': ['Tell me a bio of Amr Diab.'], 'context': ['{\n  "id" : "4632685",\n  "contents" : "\\"Amr Diab\\"\\nAmr Diab Amr Diab (; born October 11, 1961) is an Egyptian vocalist and writer. A Port Said native, he has established himself as an acclaimed recording artist and author in most Mediterranean countries. According to a research by Michael Frishkopf, he has created his style termed as \\"\\"Mediterranean Music\\"\\", a blend of Western and Egyptian rhythms. By 1992, he became the first Egyptian and Middle Eastern artist to start making high-tech music videos. Amr Diab was born on 11 October 1961 in Port Said, Egypt, into an artistic family. His father, Abdul Basset Diab, worked for the Suez Canal"\n}\n{\n  "id" : "6137188",\n  "contents" : "\\"Amr Diab\\"\\na bachelor\'s degree in Arabic Music from the Cairo Academy of Arts in 1986. Amr Diab Is married to Zeina Ashour, who is from Saudia Arabia, and he has 4 children: the first one a daughter named Nour from his first marriage to the actress Shereen Reda, one son Abdallah, and two daughters Kinzy and Jana from marriage with Zeina Ashour. Diab released his first album entitled \\"\\"Ya Tareeq\\"\\" in 1983. Diab\'s second album, \\"\\"Ghanny Men Albak\\"\\" (1984), which was the first of a series of records he released with Delta Sound, including \\"\\"Hala Hala\\"\\" (1986), \\"\\"Khalseen\\"\\" (1987), \\"\\"Mayyal\\"\\" (1988),"\n}\n{\n  "id" : "5349009",\n  "contents" : "\\"Amr Diab\\"\\n6 African Music Awards in his career. Diab won Big Apple Music Awards 2009 as Lifetime Achievements Awards and Best Singer of The Year and also won The Global Icon Award, Most Popular Artist and Best Arabic Male Artist in 2014. On September 28, 2016 Diab announced that he achieved a Guinness World Records title for Most World Music Awards for Best Selling Middle Eastern Artist !Ref Amr Diab Amr Diab (; born October 11, 1961) is an Egyptian vocalist and writer. A Port Said native, he has established himself as an acclaimed recording artist and author in most Mediterranean"\n}'], 'claim_check_methods': ['QuestionAnswerGeneration'], 'claim_check_methods_0': {'name': 'Claim Check Method by Generating Questions and Answers.\nQuestion generation model: openrouter/qwen/qwen-2.5-72b-instruct\nNumber of questions to be generated for a stament: 2\nNumber of trials to generate an answer that entails with the claim: 2\nEntailment check model: <class \'transformers.models.deberta.modeling_deberta.DebertaForSequenceClassification\'>\n\nQuestion generation instruction for the first claim:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nQuestion generation instruction for claims with preceeding text:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nAnswer generation instruction:\n    [{\'role\': \'system\', \'content\': \'You are a helpful assistant. Give a single claim answer to given question. Don\\\\â€˜t provide any additional information. Just answer the question with a brief sentence in a single claim.\'}, {\'role\': \'user\', \'content\': \'{question}\'}]\n\nTruth methods to assign a score the question(s):\n   [<TruthTorchLM.truth_methods.matrix_degree_uncertainty.MatrixDegreeUncertainty object at 0x000001CF401A3F10>, <TruthTorchLM.truth_methods.eccentricity_uncertainty.EccentricityUncertainty object at 0x000001CF401F93F0>]', 'truth_methods': ['MatrixDegreeUncertainty', 'EccentricityUncertainty'], 'truth_methods_name': ['MatrixDegreeUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x000001CF401A3DC0>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'temperature\': 3.0, \'batch_generation\': True}', 'EccentricityUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x000001CF4020A740>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'eigen_threshold\': 0.9, \'temperature\': 3.0, \'batch_generation\': True}'], 'truth_values': [[[np.float64(-0.04298634529113769), np.float64(-2.220446049250313e-16)], [np.float64(-0.07317380905151367), np.float64(-0.012083354884762532)], [np.float64(-0.04145631790161133), np.float64(-4.996003610813204e-16)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.053494658470153805), np.float64(-0.005215744660316268)], [np.float64(-0.41217454671859743), np.float64(-2.8842994970101654)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.040396995544433593), np.float64(-8.075171579963181e-05)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.04712302684783935), np.float64(-0.0014594506867158796)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.09696841955184937), np.float64(-0.0277227490915658)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.0510945463180542), np.float64(-0.0019497422546190246)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.25964558362960816), np.float64(-2.084263631098288)], [np.float64(-0.06393624544143676), np.float64(-0.007767654000479629)], [np.float64(-0.053843421936035155), np.float64(-0.006334613780708931)], [np.float64(-0.08181211471557617), np.float64(-0.04158958822727815)], [np.float64(-0.05617891550064087), np.float64(-0.006044462148088792)]]], 'normalized_truth_values': [[[np.float64(0.4892550681898532), np.float64(0.49999999999999994)], [np.float64(0.4817147059169796), np.float64(0.49697919803368973)], [np.float64(0.48963740460116534), np.float64(0.4999999999999999)], [np.int64(0), np.int64(0)], [np.float64(0.4866295237307535), np.float64(0.4986960667909353)], [np.float64(0.39839082043928403), np.float64(0.052935174754924076)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.48990212431800145), np.float64(0.499979812071061)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.48822142281312103), np.float64(0.499635137393084)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.47577687272342944), np.float64(0.49306975657511054)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.4872291416558845), np.float64(0.4995125645907605)], [np.int64(0), np.int64(0)], [np.float64(0.4354508335860288), np.float64(0.11063574771572879)], [np.float64(0.4840213814431382), np.float64(0.49805809626383485)], [np.float64(0.486542395619774), np.float64(0.49841635185045047)], [np.float64(0.4795583717459306), np.float64(0.48960410137680904)], [np.float64(0.4859589638056698), np.float64(0.498488889063744)]]]}}}