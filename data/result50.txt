{'sample_level_eval_list': {'claim_check_methods_0_truth_method_0': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}, 'claim_check_methods_0_truth_method_1': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}}, 'dataset_level_eval_list': {'claim_check_methods_0_truth_method_0': {'prr': np.float64(0.5)}, 'claim_check_methods_0_truth_method_1': {'prr': np.float64(0.5)}}, 'output_dict': {'previous_context': [{'role': 'system', 'content': 'You are a helpful assistant. Give precise answers.'}], 'user_prompt': 'Context: {context}\nQuestion: {question}', 'generation': ['Maggie Cogan was a notable figure in New York City during the 1960s, known for being the first female horse and carriage driver in Central Park. Here is a detailed biography of her life and career:\n\n### Early Life and Background\n- **Place of Birth and Upbringing**: Maggie Cogan was raised in a town near New York City. In high school, she was an active student, participating in various activities.\n- **Personal Life**: She had two unsuccessful marriages and gave birth to two sons, both of whom she gave up for adoption when her life began to unravel.\n\n### Career as a Horse and Carriage Driver\n- **Initial Fame**: In the early 1960s, Maggie Cogan made history by becoming the first female horse and carriage driver in Central Park, working for the Plaza Hotel. This achievement brought her minor celebrity status and media attention.\n- **Media Appearances**: In 1967, she appeared in a Universal newsreel with her horse and carriage, further highlighting her unique position. In 1968, she appeared on the quiz show "What\'s My Line?", where contestants tried to guess her occupation, adding to her public recognition.\n- **Career Interruption and Resumption**: Maggie left her career briefly in the 1960s but returned in 1970. During this period, she befriended Lisa Ryan, the daughter of actor Robert Ryan, who also became a horse-and-carriage driver.\n\n### Later Life and Challenges\n- **Mental Health Issues**: By 1977, while living with Lisa Ryan, Maggie began to show signs of mental illness. Her condition worsened, and her parents eventually committed her to a mental hospital.\n- **Homelessness**: After leaving her career for good, Maggie became homeless and was found living in Central Park.\n- **Documentary**: Director Michel Negroponte discovered her in Central Park and made a documentary film titled "Jupiter\'s Wife" about her life and struggles.\n\n### Legacy\n- **Cultural Impact**: Maggie Cogan\'s pioneering role as a female horse and carriage driver in Central Park, along with her media appearances, contributed to breaking gender barriers in traditionally male-dominated professions.\n- **Documentary**: The documentary "Jupiter\'s Wife" provides a poignant and detailed look into her life, struggles, and the complex journey of a woman who was both a trailblazer and a victim of personal and societal challenges.\n\nMaggie Cogan\'s story is a testament to both her resilience and the obstacles she faced, making her a notable figure in the cultural and social history of New York City.'], 'claims': [['Maggie Cogan was a notable figure in New York City during the 1960s.', 'Maggie Cogan was the first female horse and carriage driver in Central Park.', 'Maggie Cogan was raised in a town near New York City.', 'In high school, Maggie Cogan was an active student.', 'Maggie Cogan participated in various activities in high school.', 'She had two unsuccessful marriages.', 'She gave birth to two sons.', 'She gave up both of her sons for adoption when her life began to unravel.', 'In the early 1960s, Maggie Cogan became the first female horse and carriage driver in Central Park.', 'Maggie Cogan worked for the Plaza Hotel.', "Maggie Cogan's achievement brought her minor celebrity status.", "Maggie Cogan's achievement brought her media attention.", 'In 1967, she appeared in a Universal newsreel with her horse and carriage.', "In 1968, she appeared on the quiz show 'What's My Line?' where contestants tried to guess her occupation.", 'Maggie left her career briefly in the 1960s.', 'Maggie returned to her career in 1970.', 'During her career break, Maggie befriended Lisa Ryan.', 'Lisa Ryan is the daughter of actor Robert Ryan.', 'Lisa Ryan also became a horse-and-carriage driver.', 'By 1977, Maggie began to show signs of mental illness while living with Lisa Ryan.', "Maggie's condition worsened over time.", "Maggie's parents eventually committed her to a mental hospital.", 'Maggie became homeless after leaving her career.', 'Maggie was found living in Central Park.', 'Director Michel Negroponte discovered her in Central Park.', 'Michel Negroponte made a documentary film titled "Jupiter\'s Wife".', 'The documentary film "Jupiter\'s Wife" is about her life and struggles.', 'Maggie Cogan was a female horse and carriage driver in Central Park.', "Maggie Cogan's role as a female horse and carriage driver contributed to breaking gender barriers.", "Maggie Cogan's media appearances contributed to breaking gender barriers.", 'Traditionally male-dominated professions include being a horse and carriage driver.', 'The documentary "Jupiter\'s Wife" provides a detailed look into her life.', 'The documentary "Jupiter\'s Wife" covers her struggles.', 'The documentary "Jupiter\'s Wife" explores the complex journey of a woman who was both a trailblazer and a victim of personal and societal challenges.', "Maggie Cogan's story is a testament to her resilience.", "Maggie Cogan's story is a testament to the obstacles she faced.", 'Maggie Cogan is a notable figure in the cultural and social history of New York City.']], 'claim_correctness': [array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])], 'question_text': ['Tell me a bio of Maggie Cogan.'], 'context': ['{\n  "id" : "19182876",\n  "contents" : "\\"Maggie Cogan\\"\\nMaggie Cogan Maggie Cogan is a resident of New York City who became a minor celebrity in the early 1960s when she was the first female horse and carriage driver in Central Park, working for the Plaza Hotel. She appeared in a 1967 Universal newsreel with her horse and carriage, and in 1968, also appeared on quiz show What\'s My Line?, with contestants attempting to guess her occupation. After leaving her career briefly in the 1960s, she resumed it in 1970, befriending Lisa Ryan, the daughter of actor Robert Ryan, who had also become a horse-and-carriage driver. By this point,"\n}\n{\n  "id" : "19182883",\n  "contents" : "\\"Maggie Cogan\\"\\nWallkill, NY. The New York Times reported that the arrangement was short lived as Cogan returned to Central Park five weeks later. Maggie Cogan Maggie Cogan is a resident of New York City who became a minor celebrity in the early 1960s when she was the first female horse and carriage driver in Central Park, working for the Plaza Hotel. She appeared in a 1967 Universal newsreel with her horse and carriage, and in 1968, also appeared on quiz show What\'s My Line?, with contestants attempting to guess her occupation. After leaving her career briefly in the 1960s, she resumed"\n}\n{\n  "id" : "19182877",\n  "contents" : "\\"Maggie Cogan\\"\\nshe had had 2 unsuccessful marriages and given birth to two sons, both of whom she gave up when her life began to unravel. In 1977, while living with Ryan, Cogan began to show signs of mental illness and she was eventually committed to a mental hospital by her parents. Eventually, she became homeless when she left her career for good. Director Michel Negroponte discovered her living in Central Park and made the documentary film Jupiter\'s Wife about her. Cogan was raised in a town near New York City, and in high school, she was an active student, participating in"\n}'], 'claim_check_methods': ['QuestionAnswerGeneration'], 'claim_check_methods_0': {'name': 'Claim Check Method by Generating Questions and Answers.\nQuestion generation model: openrouter/qwen/qwen-2.5-72b-instruct\nNumber of questions to be generated for a stament: 2\nNumber of trials to generate an answer that entails with the claim: 2\nEntailment check model: <class \'transformers.models.deberta.modeling_deberta.DebertaForSequenceClassification\'>\n\nQuestion generation instruction for the first claim:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nQuestion generation instruction for claims with preceeding text:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nAnswer generation instruction:\n    [{\'role\': \'system\', \'content\': \'You are a helpful assistant. Give a single claim answer to given question. Don\\\\â€˜t provide any additional information. Just answer the question with a brief sentence in a single claim.\'}, {\'role\': \'user\', \'content\': \'{question}\'}]\n\nTruth methods to assign a score the question(s):\n   [<TruthTorchLM.truth_methods.matrix_degree_uncertainty.MatrixDegreeUncertainty object at 0x000001873EA04BE0>, <TruthTorchLM.truth_methods.eccentricity_uncertainty.EccentricityUncertainty object at 0x000001873EC19480>]', 'truth_methods': ['MatrixDegreeUncertainty', 'EccentricityUncertainty'], 'truth_methods_name': ['MatrixDegreeUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x000001873EBBFF10>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'temperature\': 3.0, \'batch_generation\': True}', 'EccentricityUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x000001873EC2A6B0>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'eigen_threshold\': 0.9, \'temperature\': 3.0, \'batch_generation\': True}'], 'truth_values': [[[np.float64(-0.1020301866531372), np.float64(-0.022128758027366024)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.12492798328399658), np.float64(-0.013729143230428564)], [np.float64(-0.09262848615646363), np.float64(-0.041814648668950516)], [np.float64(-0.04037699699401855), np.float64(-8.47329964646093e-05)], [np.float64(-0.22771413803100585), np.float64(-1.9418230378889736)], [np.float64(-0.045709877014160155), np.float64(-0.004576366989555658)], [np.float64(-0.19555254459381102), np.float64(-1.5704879695943077)], [np.float64(-0.059303908348083495), np.float64(-0.013735778743303062)], [np.float64(-0.5533570528030396), np.float64(-3.7787266880100776)], [np.float64(-0.2628622841835022), np.float64(-2.8490700362633317)], [np.float64(-0.6382856965065002), np.float64(-4.47213595499958)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.04644757270812988), np.float64(-0.0071910819417901894)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.042251098155975345), np.float64(-0.003215286250011773)], [np.float64(-0.057770671844482424), np.float64(-0.0034965420027742167)], [np.float64(-0.04285564422607422), np.float64(-1.1102230246251565e-16)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.15441704273223877), np.float64(-1.8802178879424183)], [np.float64(-0.07871923923492431), np.float64(-0.006725379374017737)], [np.float64(-0.08287444114685058), np.float64(-0.03276158369759352)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.13264055967330932), np.float64(-0.04749135854923725)]]], 'normalized_truth_values': [[[np.float64(0.4745145584598971), np.float64(0.4944680362332082)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.46880856069946464), np.float64(0.4965677681038269)], [np.float64(0.47685942167912315), np.float64(0.4895478607215564)], [np.float64(0.4899071219174202), np.float64(0.4999788167508965)], [np.float64(0.44331619296578323), np.float64(0.1254477133559299)], [np.float64(0.4885745200368724), np.float64(0.4988559102493459)], [np.float64(0.4512670638251621), np.float64(0.1721468389364886)], [np.float64(0.48517836657472985), np.float64(0.49656610930381384)], [np.float64(0.3650858983748587), np.float64(0.0223412336016629)], [np.float64(0.4346602259754204), np.float64(0.05472940813569069)], [np.float64(0.34563416278024567), np.float64(0.011293882208110636)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.4883901939753069), np.float64(0.49820223726165364)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.48943879652995503), np.float64(0.49919617912999303)], [np.float64(0.48556134750622354), np.float64(0.49912586538988957)], [np.float64(0.4892877284120365), np.float64(0.49999999999999994)], [np.int64(0), np.int64(0)], [np.float64(0.46147226551873394), np.float64(0.132363848488771)], [np.float64(0.48033034641812006), np.float64(0.4983186614938378)], [np.float64(0.4792932398244653), np.float64(0.49181033657422646)], [np.int64(0), np.int64(0)], [np.float64(0.4668883916594143), np.float64(0.4881293913885379)]]]}}}