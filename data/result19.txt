{'sample_level_eval_list': {'claim_check_methods_0_truth_method_0': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}, 'claim_check_methods_0_truth_method_1': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}}, 'dataset_level_eval_list': {'claim_check_methods_0_truth_method_0': {'prr': np.float64(0.5)}, 'claim_check_methods_0_truth_method_1': {'prr': np.float64(0.5)}}, 'output_dict': {'previous_context': [{'role': 'system', 'content': 'You are a helpful assistant. Give precise answers.'}], 'user_prompt': 'Context: {context}\nQuestion: {question}', 'generation': ['Ra Jong-yil (born 1940) is a former South Korean diplomat and author. He received his PhD from the University of Cambridge and has written extensively on North Korean politics and history.\n\n### Diplomatic Career:\n- **Ambassador to the United Kingdom (2001-2003):** Ra served as South Korea\'s ambassador to the United Kingdom.\n- **Ambassador to Japan (2004-2007):** He then served as South Korea\'s ambassador to Japan.\n\n### Authorship:\n- **Book on Kang Min-chul (2013):** Ra released a book about Kang Min-chul, the only person who admitted involvement in the 1983 assassination attempt on the South Korean president. Ra described Kang as "one of the countless young men sacrificed in the long rivalry between the two Koreas."\n- **"The Path Taken by Jang Song-thaek: A Rebellious Outsider" (2016):** This book explored the life and career of Jang Song-thaek, a prominent North Korean political figure. Ra\'s work made claims that Kim Jong-il did not initially intend for his son, Kim Jong-un, to succeed him as the leader of North Korea.\n\n### Contributions:\n- Ra\'s writings and diplomatic experience provide valuable insights into the complex political dynamics of the Korean Peninsula, particularly focusing on North Korea\'s internal politics and its relations with South Korea and other international actors.\n\nRa Jong-yil\'s career and writings have significantly contributed to the understanding of Korean politics and diplomacy, offering a nuanced perspective on the ongoing tensions and historical events involving North and South Korea.'], 'claims': [['Ra Jong-yil was born in 1940.', 'Ra Jong-yil is a former South Korean diplomat.', 'Ra Jong-yil is an author.', 'Ra Jong-yil received his PhD from the University of Cambridge.', 'Ra Jong-yil has written extensively on North Korean politics and history.', "Ra served as South Korea's ambassador to the United Kingdom from 2001 to 2003.", "He served as South Korea's ambassador to Japan from 2004 to 2007.", 'Ra released a book about Kang Min-chul in 2013.', 'Kang Min-chul is the only person who admitted involvement in the 1983 assassination attempt on the South Korean president.', "Ra described Kang Min-chul as 'one of the countless young men sacrificed in the long rivalry between the two Koreas.'", "'The Path Taken by Jang Song-thaek: A Rebellious Outsider' is a book published in 2016.", 'The book explores the life and career of Jang Song-thaek, a prominent North Korean political figure.', "Ra's work claimed that Kim Jong-il did not initially intend for his son, Kim Jong-un, to succeed him as the leader of North Korea.", "Ra's writings and diplomatic experience provide valuable insights into the complex political dynamics of the Korean Peninsula.", "Ra's writings and diplomatic experience focus on North Korea's internal politics.", "Ra's writings and diplomatic experience focus on North Korea's relations with South Korea.", "Ra's writings and diplomatic experience focus on North Korea's relations with other international actors.", "Ra Jong-yil's career has significantly contributed to the understanding of Korean politics and diplomacy.", "Ra Jong-yil's writings have significantly contributed to the understanding of Korean politics and diplomacy.", "Ra Jong-yil's contributions offer a nuanced perspective on the ongoing tensions involving North and South Korea.", "Ra Jong-yil's contributions offer a nuanced perspective on the historical events involving North and South Korea."]], 'claim_correctness': [array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])], 'question_text': ['Tell me a bio of Ra Jong-yil.'], 'context': ['{\n  "id" : "12063277",\n  "contents" : "\\"Ra Jong-yil\\"\\nRa Jong-yil Ra Jong-yil (; born 1940) is a former South Korean ambassador who has authored books on politics concerning North Korea. Ra received a PhD at the University of Cambridge. Ra served as South Korea\'s ambassador to the United Kingdom from 2001 to 2003 and as its ambassador to Japan from 2004 to 2007. In 2013, Ra released a book about Kang Min-chulthe only person who ever admitted involvement with an attempt to assassinate the SouthKorean president in 1983whom Ra described as \\"\\"one of the countless young men sacrificed in the long rivalry between the two Koreas and then"\n}\n{\n  "id" : "12063278",\n  "contents" : "\\"Ra Jong-yil\\"\\nforgotten\\"\\". Ra\'s 2016 book, \\"\\"The Path Taken by Jang Song‑thaek: A Rebellious Outsider\\"\\", made claims that Kim Jong‑il did not intend for his son, Kim Jong‑un, to succeed him after he died. Ra Jong-yil Ra Jong-yil (; born 1940) is a former South Korean ambassador who has authored books on politics concerning North Korea. Ra received a PhD at the University of Cambridge. Ra served as South Korea\'s ambassador to the United Kingdom from 2001 to 2003 and as its ambassador to Japan from 2004 to 2007. In 2013, Ra released a book about Kang Min-chulthe only person who ever"\n}\n{\n  "id" : "4497758",\n  "contents" : "\\"Kim Jong-chul\\"\\nKim Jong-chul Kim Jong-chul (born 25 September 1981), sometimes spelled Kim Jong Chol, is a son of former North Korean Supreme Leader Kim Jong-il. His younger brother is Kim Jong-un, now the leader of North Korea. His older half-brother was Kim Jong-nam, who was assassinated in February 2017. In 2007, Jong-chul was appointed deputy chief of a leadership division of the Workers\' Party of Korea. However, on 15 January 2009, the South Korean Yonhap News Agency reported that Kim Jong-il appointed his youngest son, Jong-un, to be his successor, passing over Jong-nam and Jong-chul. These reports were supported in April"\n}'], 'claim_check_methods': ['QuestionAnswerGeneration'], 'claim_check_methods_0': {'name': 'Claim Check Method by Generating Questions and Answers.\nQuestion generation model: openrouter/qwen/qwen-2.5-72b-instruct\nNumber of questions to be generated for a stament: 2\nNumber of trials to generate an answer that entails with the claim: 2\nEntailment check model: <class \'transformers.models.deberta.modeling_deberta.DebertaForSequenceClassification\'>\n\nQuestion generation instruction for the first claim:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nQuestion generation instruction for claims with preceeding text:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nAnswer generation instruction:\n    [{\'role\': \'system\', \'content\': \'You are a helpful assistant. Give a single claim answer to given question. Don\\\\‘t provide any additional information. Just answer the question with a brief sentence in a single claim.\'}, {\'role\': \'user\', \'content\': \'{question}\'}]\n\nTruth methods to assign a score the question(s):\n   [<TruthTorchLM.truth_methods.matrix_degree_uncertainty.MatrixDegreeUncertainty object at 0x0000019B1CFFC880>, <TruthTorchLM.truth_methods.eccentricity_uncertainty.EccentricityUncertainty object at 0x0000019B1D04D3C0>]', 'truth_methods': ['MatrixDegreeUncertainty', 'EccentricityUncertainty'], 'truth_methods_name': ['MatrixDegreeUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x0000019B1CFFFF70>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'temperature\': 3.0, \'batch_generation\': True}', 'EccentricityUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x0000019B1D06A770>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'eigen_threshold\': 0.9, \'temperature\': 3.0, \'batch_generation\': True}'], 'truth_values': [[[np.float64(-0.07744220733642578), np.float64(-0.01732790220939917)], [np.float64(-0.4702633762359619), np.float64(-2.8844055477437203)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.099108464717865), np.float64(-0.032739311586626574)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.05456006288528442), np.float64(-0.003014021061419292)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.0710456395149231), np.float64(-0.004016797312866693)], [np.float64(-0.06214402675628662), np.float64(-0.004681301244567726)], [np.float64(-0.06586438655853272), np.float64(-0.006067747515547506)], [np.float64(-0.28720593214035034), np.float64(-2.7054388313285496)], [np.float64(-0.06428493738174439), np.float64(-0.014906538994872376)], [np.float64(-0.07360552072525024), np.float64(-0.017849181030618944)], [np.float64(-0.09928869485855102), np.float64(-0.02009656650907027)], [np.float64(-0.05557063102722168), np.float64(-0.0038458007724707644)]]], 'normalized_truth_values': [[[np.float64(0.4806491182789782), np.float64(0.4956681328362704)], [np.float64(0.38455390788066923), np.float64(0.05292985836110507)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.47524314499599035), np.float64(0.4918159031091798)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.48636336690550036), np.float64(0.49924649530506837)], [np.int64(0), np.int64(0)], [np.float64(0.4822460572199981), np.float64(0.4989958020219824)], [np.float64(0.4844689912303396), np.float64(0.4988296768261191)], [np.float64(0.4835398534342198), np.float64(0.49848306777525553)], [np.float64(0.42868803832568025), np.float64(0.06265318487039881)], [np.float64(0.4839342979708583), np.float64(0.4962734342561252)], [np.float64(0.4816069231947064), np.float64(0.495537823210005)], [np.float64(0.47519819812488057), np.float64(0.494976027458408)], [np.float64(0.4861109162934488), np.float64(0.49903855099188266)]]]}}}