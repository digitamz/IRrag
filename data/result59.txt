{'sample_level_eval_list': {'claim_check_methods_0_truth_method_0': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}, 'claim_check_methods_0_truth_method_1': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}}, 'dataset_level_eval_list': {'claim_check_methods_0_truth_method_0': {'prr': np.float64(0.38153679457039535)}, 'claim_check_methods_0_truth_method_1': {'prr': np.float64(0.38153679457039535)}}, 'output_dict': {'previous_context': [{'role': 'system', 'content': 'You are a helpful assistant. Give precise answers.'}], 'user_prompt': 'Context: {context}\nQuestion: {question}', 'generation': ['Felix Arvid Ulf Kjellberg, widely known by his online persona PewDiePie, is a Swedish content creator, comedian, and video game commentator. Born on October 24, 1989, in Gothenburg, Sweden, Kjellberg initially pursued a degree in industrial economics and technology management at Chalmers University of Technology in Gothenburg. However, he dropped out in 2011 after losing interest in his studies.\n\nKjellberg registered his YouTube channel, PewDiePie, in 2010, primarily to post video game commentaries, or "Let\'s Plays," which quickly gained a significant following. His engaging and humorous style resonated with viewers, and over time, his content evolved to include more comedic formatted shows, vlogs, and challenges.\n\nPewDiePie has been a prominent figure in the YouTube community, known for his entertaining and often controversial content. Despite facing criticism and controversy, he has maintained a large and loyal subscriber base. His channel has been one of the most subscribed to on YouTube for several years.\n\nIn addition to his YouTube success, Kjellberg has ventured into other media. He starred in the web series "Scare PewDiePie," a horror-themed show produced by Maker Studios and Skybound Entertainment, which premiered on YouTube Red in February 2016. The series featured Kjellberg exploring sets based on the horror video games he had played and commented on.\n\nKjellberg has also been open about his personal views, stating that he is an agnostic atheist. His influence extends beyond entertainment, as he has used his platform to support various charitable causes and address social issues.\n\nOverall, PewDiePie\'s journey from a student creating content for fun to one of the most recognized figures in the digital entertainment space is a testament to his creativity and connection with his audience.'], 'claims': [['Felix Arvid Ulf Kjellberg is widely known by his online persona PewDiePie.', 'Felix Arvid Ulf Kjellberg is a Swedish content creator, comedian, and video game commentator.', 'Felix Arvid Ulf Kjellberg was born on October 24, 1989, in Gothenburg, Sweden.', 'Felix Arvid Ulf Kjellberg pursued a degree in industrial economics and technology management at Chalmers University of Technology in Gothenburg.', 'Felix Arvid Ulf Kjellberg dropped out of Chalmers University of Technology in 2011 after losing interest in his studies.', 'Kjellberg registered his YouTube channel, PewDiePie, in 2010.', "PewDiePie was initially used to post video game commentaries, or 'Let's Plays'.", "PewDiePie's 'Let's Plays' quickly gained a significant following.", "Kjellberg's engaging and humorous style resonated with viewers.", "Over time, PewDiePie's content evolved to include more comedic formatted shows, vlogs, and challenges.", 'PewDiePie has been a prominent figure in the YouTube community.', 'PewDiePie is known for his entertaining and often controversial content.', 'PewDiePie has maintained a large and loyal subscriber base despite facing criticism and controversy.', "PewDiePie's channel has been one of the most subscribed to on YouTube for several years.", 'Kjellberg has ventured into other media besides his YouTube success.', "Kjellberg starred in the web series 'Scare PewDiePie'.", "'Scare PewDiePie' is a horror-themed show produced by Maker Studios and Skybound Entertainment.", "'Scare PewDiePie' premiered on YouTube Red in February 2016.", 'The series featured Kjellberg exploring sets based on the horror video games he had played and commented on.', 'Kjellberg has stated that he is an agnostic atheist.', 'Kjellberg has used his platform to support various charitable causes.', 'Kjellberg has addressed social issues through his platform.', 'PewDiePie transitioned from being a student creating content for fun to becoming one of the most recognized figures in the digital entertainment space.', "PewDiePie's journey is a testament to his creativity and connection with his audience."]], 'claim_correctness': [array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,
       1, 1])], 'question_text': ['Tell me a bio of PewDiePie.'], 'context': ['{\n  "id" : "17103554",\n  "contents" : "PewDiePie\\nPewDiePie Felix Arvid Ulf Kjellberg ( ; ; born 24 October 1989), known online as PewDiePie ( ), is a Swedish YouTuber, comedian and video game commentator, formerly best known for his Let\'s Play commentaries and now mostly known for his comedic formatted shows. Born in Gothenburg, Sweden, PewDiePie originally pursued a degree in industrial economics and technology management at Chalmers University of Technology in Gothenburg. In 2010, during his time at the university, he registered a YouTube account under the name PewDiePie. The following year, he dropped out of Chalmers after losing interest in his degree field, much to"\n}\n{\n  "id" : "1469952",\n  "contents" : "PewDiePie\\nYouTube because I was bored, not to become famous.\\"\\" In June 2016, Kjellberg announced he had been evicted from his recording studio after his landlord confronted him for being too loud. Kjellberg has stated on his YouTube channel that he is an agnostic atheist. PewDiePie Felix Arvid Ulf Kjellberg ( ; ; born 24 October 1989), known online as PewDiePie ( ), is a Swedish YouTuber, comedian and video game commentator, formerly best known for his Let\'s Play commentaries and now mostly known for his comedic formatted shows. Born in Gothenburg, Sweden, PewDiePie originally pursued a degree in industrial economics"\n}\n{\n  "id" : "2442685",\n  "contents" : "\\"Scare PewDiePie\\"\\nScare PewDiePie Scare PewDiePie (stylized on the web as SCARE PEWDIEPIE) was an American web television series starring Swedish YouTube personality Felix Kjellberg. The series was produced by Maker Studios (now Disney Digital Network) and Skybound Entertainment, with Robert Kirkman serving as executive producer, and premiered on February 10, 2016 exclusively for YouTube Red, YouTube\'s subscription service. It featured PewDiePie exploring sets, designed and based on the horror video games which PewDiePie played and commented over on his YouTube channel. 10 episodes were produced and filmed in Los Angeles, California during September 2015. There was a planned second season that"\n}'], 'claim_check_methods': ['QuestionAnswerGeneration'], 'claim_check_methods_0': {'name': 'Claim Check Method by Generating Questions and Answers.\nQuestion generation model: openrouter/qwen/qwen-2.5-72b-instruct\nNumber of questions to be generated for a stament: 2\nNumber of trials to generate an answer that entails with the claim: 2\nEntailment check model: <class \'transformers.models.deberta.modeling_deberta.DebertaForSequenceClassification\'>\n\nQuestion generation instruction for the first claim:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nQuestion generation instruction for claims with preceeding text:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nAnswer generation instruction:\n    [{\'role\': \'system\', \'content\': \'You are a helpful assistant. Give a single claim answer to given question. Don\\\\â€˜t provide any additional information. Just answer the question with a brief sentence in a single claim.\'}, {\'role\': \'user\', \'content\': \'{question}\'}]\n\nTruth methods to assign a score the question(s):\n   [<TruthTorchLM.truth_methods.matrix_degree_uncertainty.MatrixDegreeUncertainty object at 0x000001ED28194FD0>, <TruthTorchLM.truth_methods.eccentricity_uncertainty.EccentricityUncertainty object at 0x000001ED283D94B0>]', 'truth_methods': ['MatrixDegreeUncertainty', 'EccentricityUncertainty'], 'truth_methods_name': ['MatrixDegreeUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x000001ED2837FE80>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'temperature\': 3.0, \'batch_generation\': True}', 'EccentricityUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x000001ED283E8E50>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'eigen_threshold\': 0.9, \'temperature\': 3.0, \'batch_generation\': True}'], 'truth_values': [[[np.float64(-0.04568071365356445), np.float64(-5.551115123125783e-17)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.06532366275787353), np.float64(-0.010249974581075627)], [np.float64(-0.051587972640991214), np.float64(-0.0005453710644128806)], [np.float64(-0.5692409348487854), np.float64(-3.7787266880100807)], [np.float64(-0.067766432762146), np.float64(-0.012662784720162468)], [np.float64(-0.05550116539001465), np.float64(-0.0023048578492255167)], [np.float64(-0.06154004812240601), np.float64(-0.004631487820971059)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.049976744651794434), np.float64(-0.0038018112463229503)], [np.float64(-0.07474359273910522), np.float64(-0.006817673618217501)], [np.float64(-0.06319232940673829), np.float64(-0.009473032238263346)], [np.float64(-0.04310431003570556), np.float64(-0.006451662661665636)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.08945780754089355), np.float64(-0.019974443964459465)]]], 'normalized_truth_values': [[[np.float64(0.4885818070724174), np.float64(0.5)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.4836748890811913), np.float64(0.4974375287895499)], [np.float64(0.4871058663297468), np.float64(0.49986365723727616)], [np.float64(0.3614119936155749), np.float64(0.022341233601662833)], [np.float64(0.48306487223080524), np.float64(0.4968343461198719)], [np.float64(0.48612826931910297), np.float64(0.4994237857927822)], [np.float64(0.4846198416122254), np.float64(0.49884213011451445)], [np.int64(0), np.int64(0)], [np.float64(0.48750841372239473), np.float64(0.4990495483332197)], [np.float64(0.4813227961852045), np.float64(0.49829558819729125)], [np.float64(0.48420717271784613), np.float64(0.4976317596505707)], [np.float64(0.48922559066055854), np.float64(0.49838708992922054)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.47765045085401925), np.float64(0.49500655503084307)]]]}}}