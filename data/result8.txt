{'sample_level_eval_list': {'claim_check_methods_0_truth_method_0': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}, 'claim_check_methods_0_truth_method_1': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}}, 'dataset_level_eval_list': {'claim_check_methods_0_truth_method_0': {'prr': np.float64(0.700722948348553)}, 'claim_check_methods_0_truth_method_1': {'prr': np.float64(0.700722948348553)}}, 'output_dict': {'previous_context': [{'role': 'system', 'content': 'You are a helpful assistant. Give precise answers.'}], 'user_prompt': 'Context: {context}\nQuestion: {question}', 'generation': ['Isla Lang Fisher, born on 3 February 1976, is an accomplished Australian actress, voice actress, and author. She was born in Muscat, Oman, to Scottish parents, Elspeth Reid and Brian Fisher. Her father worked as a banker for the United Nations in Oman. At age six, Fisher and her family moved to Perth, Western Australia, after a brief period in their hometown of Bathgate, Scotland. She has four siblings and describes her upbringing in Perth as "great" with a "very outdoorsy life."\n\nFisher began her acting career early, appearing in television commercials as a child. She gained prominence for her role as Shannon Reed on the Australian soap opera "Home and Away" from 1994 to 1997, which earned her two Logie Award nominations. This role helped launch her career in the entertainment industry.\n\nFisher made the successful transition to Hollywood with her performance in the live-action film adaptation of "Scooby-Doo" (2002). She has since become well-known for her roles in various popular films, including "Wedding Crashers" (2005), "Confessions of a Shopaholic" (2009), and "The Great."\n\nIn addition to her acting career, Fisher is a published author. She is also known for her philanthropic efforts. In 2014 and 2015, she donated her signed shoes for the Small Steps Project Celebrity Shoe Auction. In December 2015, Fisher and her husband, actor Sacha Baron Cohen, donated £335,000 (US$500,000) to Save the Children to fund a measles vaccination program for children in Northern Syria and the same amount to the International Rescue Committee to assist Syrian refugees.\n\nFisher has been married to Sacha Baron Cohen since 2010, and they have three children together. She is also known to be of Jewish heritage and has described herself as keeping the Jewish Sabbath.'], 'claims': [['Isla Lang Fisher was born on 3 February 1976.', 'Isla Lang Fisher is an accomplished Australian actress, voice actress, and author.', 'Isla Lang Fisher was born in Muscat, Oman.', "Isla Lang Fisher's parents are Elspeth Reid and Brian Fisher.", "Isla Lang Fisher's father worked as a banker for the United Nations in Oman.", 'Isla Lang Fisher moved to Perth, Western Australia, at age six.', 'Isla Lang Fisher lived in Bathgate, Scotland, for a brief period.', 'Isla Lang Fisher has four siblings.', "Isla Lang Fisher describes her upbringing in Perth as 'great' with a 'very outdoorsy life.'", 'Fisher began her acting career early.', 'Fisher appeared in television commercials as a child.', "Fisher gained prominence for her role as Shannon Reed on the Australian soap opera 'Home and Away' from 1994 to 1997.", "Fisher's role as Shannon Reed earned her two Logie Award nominations.", "Fisher's role as Shannon Reed helped launch her career in the entertainment industry.", "Fisher made the successful transition to Hollywood with her performance in the live-action film adaptation of 'Scooby-Doo' in 2002.", 'Fisher has become well-known for her roles in various popular films.', "Fisher appeared in the film 'Wedding Crashers' in 2005.", "Fisher appeared in the film 'Confessions of a Shopaholic' in 2009.", "Fisher appeared in the film 'The Great.'", 'Fisher is a published author.', 'Fisher is known for her philanthropic efforts.', 'In 2014 and 2015, Fisher donated her signed shoes for the Small Steps Project Celebrity Shoe Auction.', 'In December 2015, Fisher and her husband, actor Sacha Baron Cohen, donated £335,000 to Save the Children to fund a measles vaccination program for children in Northern Syria.', 'In December 2015, Fisher and her husband, actor Sacha Baron Cohen, donated the same amount to the International Rescue Committee to assist Syrian refugees.', 'Fisher has been married to Sacha Baron Cohen since 2010.', 'Fisher and Sacha Baron Cohen have three children together.', 'Fisher is of Jewish heritage.', 'Fisher has described herself as keeping the Jewish Sabbath.']], 'claim_correctness': [array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,
       1, 1, 1, 1, 1, 1])], 'question_text': ['Tell me a bio of Isla Fisher.'], 'context': ['{\n  "id" : "4929527",\n  "contents" : "\\"Isla Fisher\\"\\nIsla Fisher Isla Lang Fisher (; born 3 February 1976) is an Australian actress, voice actress, and author. Born to Scottish parents in Oman, she moved to Australia at age six. After appearing in television commercials at a young age, Fisher came to prominence for her portrayal of Shannon Reed on the soap opera \\"\\"Home and Away\\"\\" from 1994 to 1997, garnering two Logie Award nominations. Fisher made a successful transition to Hollywood in the live-action film adaptation of \\"\\"Scooby-Doo\\"\\" (2002), and has since achieved fame for her roles in \\"\\"Wedding Crashers\\"\\" (2005), \\"\\"Confessions of a Shopaholic\\"\\" (2009), \\"\\"The Great"\n}\n{\n  "id" : "10504502",\n  "contents" : "\\"Isla Fisher\\"\\nAyala (איילה), the Hebrew word for a doe, and has described herself as keeping the Jewish Sabbath. In 2014 and 2015, Fisher donated her signed shoes for Small Steps Project Celebrity Shoe Auction. In December 2015, Fisher and her husband Baron Cohen donated £335,000 (US$500,000) to Save the Children as part of a program to vaccinate children in Northern Syria against measles, and the same amount to the International Rescue Committee also aimed at helping Syrian refugees. Isla Fisher Isla Lang Fisher (; born 3 February 1976) is an Australian actress, voice actress, and author. Born to Scottish parents in"\n}\n{\n  "id" : "12107640",\n  "contents" : "\\"Isla Fisher\\"\\nseries. She has been married to Sacha Baron Cohen since 2010 and has three children. Fisher was born in Muscat, Oman, the daughter of Scottish parents Elspeth Reid and Brian Fisher. Her father worked as a banker in Oman for the United Nations at that time. When she was a child, Fisher and her family moved back to their hometown of Bathgate in Scotland, then to Perth, Western Australia, when she was 6 years old. She has four siblings and has said that she had a \\"\\"great\\"\\" upbringing in Perth with a \\"\\"very outdoorsy life.\\"\\" Fisher has stated that her"\n}'], 'claim_check_methods': ['QuestionAnswerGeneration'], 'claim_check_methods_0': {'name': 'Claim Check Method by Generating Questions and Answers.\nQuestion generation model: openrouter/qwen/qwen-2.5-72b-instruct\nNumber of questions to be generated for a stament: 2\nNumber of trials to generate an answer that entails with the claim: 2\nEntailment check model: <class \'transformers.models.deberta.modeling_deberta.DebertaForSequenceClassification\'>\n\nQuestion generation instruction for the first claim:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nQuestion generation instruction for claims with preceeding text:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nAnswer generation instruction:\n    [{\'role\': \'system\', \'content\': \'You are a helpful assistant. Give a single claim answer to given question. Don\\\\‘t provide any additional information. Just answer the question with a brief sentence in a single claim.\'}, {\'role\': \'user\', \'content\': \'{question}\'}]\n\nTruth methods to assign a score the question(s):\n   [<TruthTorchLM.truth_methods.matrix_degree_uncertainty.MatrixDegreeUncertainty object at 0x000001A81BBC4BB0>, <TruthTorchLM.truth_methods.eccentricity_uncertainty.EccentricityUncertainty object at 0x000001A81BDD9450>]', 'truth_methods': ['MatrixDegreeUncertainty', 'EccentricityUncertainty'], 'truth_methods_name': ['MatrixDegreeUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x000001A81BD7FFA0>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'temperature\': 3.0, \'batch_generation\': True}', 'EccentricityUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x000001A81BDEA6E0>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'eigen_threshold\': 0.9, \'temperature\': 3.0, \'batch_generation\': True}'], 'truth_values': [[[np.float64(-0.04262776374816894), np.float64(-5.551115123125783e-16)], [np.float64(-0.08592419385910034), np.float64(-0.043646840030304446)], [np.float64(-0.5853359031677247), np.float64(-3.085317421020579)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.6894944930076599), np.float64(-4.47213595499958)], [np.float64(-0.27417444944381714), np.float64(-1.9548220262688158)], [np.float64(-0.05357494831085205), np.float64(-0.003248170864888378)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.2794534826278687), np.float64(-1.7885465193173355)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.1643183422088623), np.float64(-1.7888558916025306)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.06349321365356446), np.float64(-0.016455045876576202)], [np.float64(-0.044584741592407225), np.float64(-0.00020695053463126722)], [np.float64(-0.07401887893676758), np.float64(-0.02168028471339578)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.10703556776046753), np.float64(-0.025862632902898808)], [np.float64(-0.13883566856384277), np.float64(-0.025240973677656542)], [np.float64(-0.2415919804573059), np.float64(-1.96635906433866)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.042764139175415036), np.float64(-5.551115123125783e-17)], [np.float64(-0.2654703712463379), np.float64(-1.7888543819998324)], [np.float64(-0.514494469165802), np.float64(-3.7790246347695264)], [np.float64(-0.05708788633346558), np.float64(-0.009781348217347219)]]], 'normalized_truth_values': [[[np.float64(0.4893446725203593), np.float64(0.49999999999999983)], [np.float64(0.4785321579412213), np.float64(0.48909002193885887)], [np.float64(0.3577057288154643), np.float64(0.04371697620646818)], [np.int64(0), np.int64(0)], [np.float64(0.3341455352285362), np.float64(0.011293882208110636)], [np.float64(0.43188256221679083), np.float64(0.1240285165125752)], [np.float64(0.4866094656455079), np.float64(0.49918795799773963)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.4305877671650838), np.float64(0.14325101691979936)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.45901259639908765), np.float64(0.14321305179923433)], [np.int64(0), np.int64(0)], [np.float64(0.48413202705834574), np.float64(0.4958863313514398)], [np.float64(0.488855660599804), np.float64(0.49994826236652684)], [np.float64(0.48150372426917376), np.float64(0.49458014111348725)], [np.int64(0), np.int64(0)], [np.float64(0.47326662601393327), np.float64(0.49353470214368717)], [np.float64(0.46534672779384567), np.float64(0.49369009158413346)], [np.float64(0.439894069549153), np.float64(0.12278049714199442)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.4893105941966417), np.float64(0.5)], [np.float64(0.4340194484387633), np.float64(0.14321323703222505)], [np.float64(0.3741405094907366), np.float64(0.02233472674397325)], [np.float64(0.48573190321528076), np.float64(0.49755468244189893)]]]}}}