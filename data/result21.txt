{'sample_level_eval_list': {'claim_check_methods_0_truth_method_0': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}, 'claim_check_methods_0_truth_method_1': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}}, 'dataset_level_eval_list': {'claim_check_methods_0_truth_method_0': {'prr': np.float64(0.8606227390868821)}, 'claim_check_methods_0_truth_method_1': {'prr': np.float64(0.8606227390868821)}}, 'output_dict': {'previous_context': [{'role': 'system', 'content': 'You are a helpful assistant. Give precise answers.'}], 'user_prompt': 'Context: {context}\nQuestion: {question}', 'generation': ['**Song Kang-ho Bio:**\n\n**Name:** Song Kang-ho  \n**Date of Birth:** January 17, 1967  \n**Nationality:** South Korean  \n**Profession:** Actor\n\n**Career:**\n\n- **Debut:** Song Kang-ho made his debut in the film "The Day a Pig Fell into the Well" in 1996.\n- **Rise to Prominence:** He gained national recognition for his critically acclaimed performances in several films, including "No. 3" (1997), "Joint Security Area" (2000), "Memories of Murder" (2003), and "The Host" (2006).\n- **International Recognition:** Song\'s international breakthrough came with his role in the science fiction film "Snowpiercer" (2013).\n- **Versatility:** He has showcased his acting prowess in a variety of genres, from dramas to comedies and action films. Notable works include the period films "The Throne" (2015), which offers a new perspective on the relationship between King Yeongjo and Prince Sado, and "The Age of Shadows" (2016), a period action film. He also starred in "A Taxi Driver" (2017), which depicts the 1980 Gwangju Democratization Movement.\n- **Awards and Recognition:** Song Kang-ho is widely regarded as one of the most talented and versatile actors in South Korea. His performances have earned him numerous awards and nominations.\n\n**Background:**\n\n- **Education:** Song Kang-ho never received formal training as an actor. He began his career in social activities before transitioning to acting.\n- **Personal Life:** While details about his personal life are not extensively publicized, his professional achievements and contributions to South Korean cinema have made him a significant figure in the industry.\n\n**Legacy:**\nTogether with fellow actors Choi Min-sik and Sol Kyung-gu, Song Kang-ho is considered one of the leading actors in South Korea, known for his natural acting style and ability to transform into a wide range of characters.'], 'claims': [['The name of the person is Song Kang-ho.', 'January 17, 1967 is the date of birth.', "The person's nationality is South Korean.", 'The profession mentioned is Actor.', "The paragraph about 'Career:' does not contain any specific factual claims.", "Song Kang-ho made his debut in the film 'The Day a Pig Fell into the Well' in 1996.", 'He gained national recognition for his critically acclaimed performances in several films.', "He performed in the film 'No. 3' in 1997.", "He performed in the film 'Joint Security Area' in 2000.", "He performed in the film 'Memories of Murder' in 2003.", "He performed in the film 'The Host' in 2006.", "Song's international breakthrough came with his role in the science fiction film Snowpiercer in 2013.", 'He has showcased his acting prowess in a variety of genres, from dramas to comedies and action films.', 'The period film "The Throne" (2015) offers a new perspective on the relationship between King Yeongjo and Prince Sado.', 'He starred in the period action film "The Age of Shadows" (2016).', 'He also starred in "A Taxi Driver" (2017), which depicts the 1980 Gwangju Democratization Movement.', 'Song Kang-ho is widely regarded as one of the most talented and versatile actors in South Korea.', "Song Kang-ho's performances have earned him numerous awards and nominations.", 'Song Kang-ho never received formal training as an actor.', 'Song Kang-ho began his career in social activities before transitioning to acting.', 'Details about his personal life are not extensively publicized.', 'His professional achievements and contributions to South Korean cinema have made him a significant figure in the industry.', 'Choi Min-sik is considered one of the leading actors in South Korea.', 'Sol Kyung-gu is considered one of the leading actors in South Korea.', 'Song Kang-ho is considered one of the leading actors in South Korea.', 'Song Kang-ho is known for his natural acting style.', 'Song Kang-ho has the ability to transform into a wide range of characters.']], 'claim_correctness': [array([ 1,  1,  1,  1,  0,  1,  1,  0,  1,  1,  1,  1,  1, -1,  1,  1,  1,
        1,  1,  1,  1,  1,  1,  1,  1,  1, -1])], 'question_text': ['Tell me a bio of Song Kang.'], 'context': ['{\n  "id" : "2510561",\n  "contents" : "\\"Song Kang-ho\\"\\nSong Kang-ho Song Kang-ho (; born January 17, 1967) is a South Korean actor. Following his debut appearance in \\"\\"The Day a Pig Fell into the Well\\"\\", Song came to national prominence with a series of critically acclaimed performances in films such as \\"\\"No. 3\\"\\", \\"\\"Joint Security Area\\"\\", \\"\\"Memories of Murder\\"\\" and \\"\\"The Host\\"\\". He also starred in the internationally released science fiction film \\"\\"Snowpiercer\\"\\". Together with Choi Min-sik and Sol Kyung-gu, Song is considered to be one of the most talented top actors in South Korea. Song Kang-ho never professionally trained as an actor, beginning his career in social"\n}\n{\n  "id" : "4485014",\n  "contents" : "\\"Kang Song-san\\"\\nKang Song-san Kang Song-san (3 March 1931 – 2007) was a North Korean politician who served as Premier of North Korea from 1984 to 1986 and again from 1992 to 1997. He succeeded Li Jong-ok in his first term and Yon Hyong-muk in his second term. He was born in North Hamgyong. He graduated from Mangyongdae Revolutionary School and from Kim Il-sung University and went to study in the Soviet Union in Moscow State University. He became an instructor in the Central Committee of the Workers\' Party of Korea in 1955. Candidate member of the political politburo in 1973, Deputy"\n}\n{\n  "id" : "2510567",\n  "contents" : "\\"Song Kang-ho\\"\\ncritically acclaimed films; including period film \\"\\"The Throne\\"\\", a new spin on the relationship between King Yeongjo and Prince Sado; period action film \\"\\"The Age of Shadows\\"\\", and \\"\\"A Taxi Driver\\"\\", a film which depicts the 1980 Gwangju Democratization Movement. Song Kang-ho Song Kang-ho (; born January 17, 1967) is a South Korean actor. Following his debut appearance in \\"\\"The Day a Pig Fell into the Well\\"\\", Song came to national prominence with a series of critically acclaimed performances in films such as \\"\\"No. 3\\"\\", \\"\\"Joint Security Area\\"\\", \\"\\"Memories of Murder\\"\\" and \\"\\"The Host\\"\\". He also starred in the internationally"\n}'], 'claim_check_methods': ['QuestionAnswerGeneration'], 'claim_check_methods_0': {'name': 'Claim Check Method by Generating Questions and Answers.\nQuestion generation model: openrouter/qwen/qwen-2.5-72b-instruct\nNumber of questions to be generated for a stament: 2\nNumber of trials to generate an answer that entails with the claim: 2\nEntailment check model: <class \'transformers.models.deberta.modeling_deberta.DebertaForSequenceClassification\'>\n\nQuestion generation instruction for the first claim:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nQuestion generation instruction for claims with preceeding text:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nAnswer generation instruction:\n    [{\'role\': \'system\', \'content\': \'You are a helpful assistant. Give a single claim answer to given question. Don\\\\‘t provide any additional information. Just answer the question with a brief sentence in a single claim.\'}, {\'role\': \'user\', \'content\': \'{question}\'}]\n\nTruth methods to assign a score the question(s):\n   [<TruthTorchLM.truth_methods.matrix_degree_uncertainty.MatrixDegreeUncertainty object at 0x0000019B1CFFC880>, <TruthTorchLM.truth_methods.eccentricity_uncertainty.EccentricityUncertainty object at 0x0000019B1D04D3C0>]', 'truth_methods': ['MatrixDegreeUncertainty', 'EccentricityUncertainty'], 'truth_methods_name': ['MatrixDegreeUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x0000019B1CFFFF70>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'temperature\': 3.0, \'batch_generation\': True}', 'EccentricityUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x0000019B1D06A770>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'eigen_threshold\': 0.9, \'temperature\': 3.0, \'batch_generation\': True}'], 'truth_values': [[[np.float64(-0.22783164024353028), np.float64(-2.1908902300206643)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.04241032600402832), np.float64(-2.220446049250313e-16)], [np.float64(-0.048681726455688475), np.float64(-0.00036698941808677166)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.46862738370895385), np.float64(-3.692886219777297)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.15027589082717896), np.float64(-2.086873888776251)], [np.float64(-0.2409123659133911), np.float64(-2.0325358451013495)], [np.float64(-0.45805925846099854), np.float64(-2.874809231032433)], [np.float64(-0.05541964292526245), np.float64(-0.007243259662989665)], [np.float64(-0.04533516883850098), np.float64(-0.004385314013441388)], [np.float64(-0.08933714389801026), np.float64(-0.01398792369363161)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.048657243251800535), np.float64(-0.0020425975786843575)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.061217041015625), np.float64(-0.011107237341989817)]]], 'normalized_truth_values': [[[np.float64(0.4432871951467763), np.float64(0.10057153747411851)], [np.int64(0), np.int64(0)], [np.float64(0.48939900739505476), np.float64(0.49999999999999994)], [np.float64(0.4878319713860532), np.float64(0.49990825264650807)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.3849411748872509), np.float64(0.02429508294286941)], [np.int64(0), np.int64(0)], [np.float64(0.46250156917934876), np.float64(0.11037917107612644)], [np.float64(0.4400615247600324), np.float64(0.11582896642692844)], [np.float64(0.3874463225557932), np.float64(0.05341297426256173)], [np.float64(0.48614863427135646), np.float64(0.49818919300121617)], [np.float64(0.4886681485655342), np.float64(0.49890367325359214)], [np.float64(0.4776805565741192), np.float64(0.4965030760943359)], [np.int64(0), np.int64(0)], [np.float64(0.48783808856384153), np.float64(0.4994893507828733)], [np.int64(0), np.int64(0)], [np.float64(0.48470051738191244), np.float64(0.4972232192122312)]]]}}}