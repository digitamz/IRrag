{'sample_level_eval_list': {'claim_check_methods_0_truth_method_0': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}, 'claim_check_methods_0_truth_method_1': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}}, 'dataset_level_eval_list': {'claim_check_methods_0_truth_method_0': {'prr': np.float64(-1.5798012370870465)}, 'claim_check_methods_0_truth_method_1': {'prr': np.float64(-0.6964651595020042)}}, 'output_dict': {'previous_context': [{'role': 'system', 'content': 'You are a helpful assistant. Give precise answers.'}], 'user_prompt': 'Context: {context}\nQuestion: {question}', 'generation': ['Anna May Wong, born Wong Liu Tsong on January 3, 1905, in Los Angeles, was a pioneering American actress and is considered the first Chinese American Hollywood movie star to gain international recognition. She was born to second-generation Hong Kong-Chinese-American parents and developed a passion for the movies at a young age, which led her to begin acting in films early in her life.\n\nWong\'s career was extensive and diverse, spanning silent film, sound film, television, stage, and radio. One of her notable early roles was in the silent film "The Toll of the Sea" (1922), one of the first movies to use Technicolor. Despite the racist stereotypes and limited roles available to Asian actors during her time, Wong managed to achieve a level of success and recognition that was unprecedented for a Chinese American actress.\n\nWong faced significant discrimination and typecasting throughout her career, often being offered roles that perpetuated negative stereotypes of Asian women. Despite these challenges, she continued to push boundaries and sought to portray more nuanced and complex characters. Her talent and determination allowed her to perform in international productions, including in Europe, where she found greater acceptance and opportunities.\n\nIn the later years of her life, Wong was sometimes used as a symbol of a "tragic diva," but her legacy has been re-evaluated and celebrated in recent decades. Her life and career have been the subject of several works, including the award-winning fictional play "China Doll, The Imagined Life of an American Actress" by Elizabeth Wong (1995) and Anthony Chan\'s biography "Perpetually Cool: The Many Lives of Anna May Wong (1905–1961)" (2003). An illustrated biography for children, "Shining Star: The Anna May Wong Story," was published in 2009.\n\nWong\'s contributions to the film industry and her role in breaking barriers for Asian American actors have been recognized in various retrospectives and exhibitions, including those at the Museum of Modern Art and the American Museum of the Moving Image in New York City. She passed away on February 3, 1961, leaving behind a legacy as a trailblazer and an influence on generations of actors.'], 'claims': [['Anna May Wong was born Wong Liu Tsong on January 3, 1905, in Los Angeles.', 'Anna May Wong is considered the first Chinese American Hollywood movie star to gain international recognition.', 'Anna May Wong was born to second-generation Hong Kong-Chinese-American parents.', 'Anna May Wong developed a passion for the movies at a young age.', 'Anna May Wong began acting in films early in her life.', "Wong's career was extensive and diverse, spanning silent film, sound film, television, stage, and radio.", "One of Wong's notable early roles was in the silent film 'The Toll of the Sea' (1922).", "'The Toll of the Sea' (1922) was one of the first movies to use Technicolor.", 'Wong managed to achieve a level of success and recognition that was unprecedented for a Chinese American actress.', "During Wong's time, Asian actors faced racist stereotypes and limited roles.", 'Wong faced significant discrimination and typecasting throughout her career.', 'Wong was often offered roles that perpetuated negative stereotypes of Asian women.', 'Despite challenges, Wong continued to push boundaries.', 'Wong sought to portray more nuanced and complex characters.', "Wong's talent and determination allowed her to perform in international productions.", 'Wong found greater acceptance and opportunities in Europe.', "In the later years of her life, Wong was sometimes used as a symbol of a 'tragic diva.'", "Wong's legacy has been re-evaluated and celebrated in recent decades.", "Wong's life and career have been the subject of several works.", "The award-winning fictional play 'China Doll, The Imagined Life of an American Actress' by Elizabeth Wong was published in 1995.", "Anthony Chan's biography 'Perpetually Cool: The Many Lives of Anna May Wong (1905–1961)' was published in 2003.", "An illustrated biography for children, 'Shining Star: The Anna May Wong Story,' was published in 2009.", "Wong's contributions to the film industry have been recognized in various retrospectives and exhibitions.", "Wong's role in breaking barriers for Asian American actors has been recognized in various retrospectives and exhibitions.", "Wong's contributions and role have been recognized at the Museum of Modern Art.", "Wong's contributions and role have been recognized at the American Museum of the Moving Image in New York City.", 'Wong passed away on February 3, 1961.', 'Wong left behind a legacy as a trailblazer.', 'Wong influenced generations of actors.']], 'claim_correctness': [array([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1])], 'question_text': ['Tell me a bio of Anna May Wong.'], 'context': ['{\n  "id" : "11585490",\n  "contents" : "\\"Anna May Wong\\"\\nstar, is permanent. An illustrated biography for children, \\"\\"Shining Star: The Anna May Wong Story\\"\\", was published in 2009. Anna May Wong Anna May Wong (born Wong Liu Tsong, January 3, 1905 – February 3, 1961) was an American actress, considered to be the first Hong Kong-Chinese American Hollywood movie star, as well as the first Chinese American actress to gain international recognition. Her long and varied career spanned silent film, sound film, television, stage, and radio. Born in Los Angeles to second-generation Hong Kong-Chinese-American parents, Wong became infatuated with the movies and began acting in films at an early"\n}\n{\n  "id" : "14178347",\n  "contents" : "\\"Anna May Wong\\"\\nAnna May Wong Anna May Wong (born Wong Liu Tsong, January 3, 1905 – February 3, 1961) was an American actress, considered to be the first Hong Kong-Chinese American Hollywood movie star, as well as the first Chinese American actress to gain international recognition. Her long and varied career spanned silent film, sound film, television, stage, and radio. Born in Los Angeles to second-generation Hong Kong-Chinese-American parents, Wong became infatuated with the movies and began acting in films at an early age. During the silent film era, she acted in \\"\\"The Toll of the Sea\\"\\" (1922), one of the first"\n}\n{\n  "id" : "12764399",\n  "contents" : "\\"Anna May Wong\\"\\nwas used briefly as a symbol of a \\"\\"tragic diva\\"\\". Her life was the subject of \\"\\"China Doll, The Imagined Life of an American Actress\\"\\", an award-winning fictional play written by Elizabeth Wong in 1995. As the centennial of Wong\'s birth approached, a re-examination of her life and career took shape; three major works on the actress appeared and comprehensive retrospectives of her films were held at both the Museum of Modern Art and the American Museum of the Moving Image in New York City. Anthony Chan\'s 2003 biography, \\"\\"Perpetually Cool: The Many Lives of Anna May Wong (1905–1961)\\"\\", was"\n}'], 'claim_check_methods': ['QuestionAnswerGeneration'], 'claim_check_methods_0': {'name': 'Claim Check Method by Generating Questions and Answers.\nQuestion generation model: openrouter/qwen/qwen-2.5-72b-instruct\nNumber of questions to be generated for a stament: 2\nNumber of trials to generate an answer that entails with the claim: 2\nEntailment check model: <class \'transformers.models.deberta.modeling_deberta.DebertaForSequenceClassification\'>\n\nQuestion generation instruction for the first claim:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nQuestion generation instruction for claims with preceeding text:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nAnswer generation instruction:\n    [{\'role\': \'system\', \'content\': \'You are a helpful assistant. Give a single claim answer to given question. Don\\\\‘t provide any additional information. Just answer the question with a brief sentence in a single claim.\'}, {\'role\': \'user\', \'content\': \'{question}\'}]\n\nTruth methods to assign a score the question(s):\n   [<TruthTorchLM.truth_methods.matrix_degree_uncertainty.MatrixDegreeUncertainty object at 0x000001D8AB59E9E0>, <TruthTorchLM.truth_methods.eccentricity_uncertainty.EccentricityUncertainty object at 0x000001D8AB6E1510>]', 'truth_methods': ['MatrixDegreeUncertainty', 'EccentricityUncertainty'], 'truth_methods_name': ['MatrixDegreeUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x000001D8AB4B0C70>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'temperature\': 3.0, \'batch_generation\': True}', 'EccentricityUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x000001D8AB6F8CA0>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'eigen_threshold\': 0.9, \'temperature\': 3.0, \'batch_generation\': True}'], 'truth_values': [[[np.float64(-0.04109206199645996), np.float64(-1.6653345369377348e-16)], [np.float64(-0.05512634515762329), np.float64(-0.00801443660826473)], [np.float64(-0.05421886682510376), np.float64(-0.0026861337168563315)], [np.float64(-0.04525756120681763), np.float64(-0.005255123716410015)], [np.float64(-0.03912405014038086), np.float64(-0.0015532011506287358)], [np.float64(-0.03997997283935547), np.float64(-1.6653345369377348e-16)], [np.float64(-0.04035773277282715), np.float64(-3.885780586188048e-16)], [np.float64(-0.0459037184715271), np.float64(-0.0017463156782440148)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.05003875494003296), np.float64(-0.0015961214164085247)], [np.float64(-0.050000741481781005), np.float64(-0.0012569193144200685)], [np.float64(-0.10750035524368286), np.float64(-0.023339665034642354)], [np.float64(-0.04811554193496704), np.float64(-0.0008665060072167718)], [np.float64(-0.06025749683380127), np.float64(-0.001982232993849309)], [np.float64(-0.053608150482177735), np.float64(-0.004365109246739884)], [np.float64(-0.0378626823425293), np.float64(-3.3306690738754696e-16)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.061347014904022217), np.float64(-0.0034530210451810817)], [np.float64(-0.03820046424865722), np.float64(-0.00021497069515985512)], [np.float64(-0.5521726512908935), np.float64(-4.472135954999579)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.04519500732421875), np.float64(-3.3306690738754696e-16)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.0774094820022583), np.float64(-0.016843250047287872)], [np.float64(-0.05332497119903565), np.float64(-0.0063919012689898635)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.043910551071166995), np.float64(-5.551115123125783e-16)], [np.float64(-0.07514298677444459), np.float64(-0.0035723267587823293)], [np.float64(-0.04570436716079712), np.float64(-0.0010421820856327257)]]], 'normalized_truth_values': [[[np.float64(0.4897284298050022), np.float64(0.49999999999999994)], [np.float64(0.4862219027381924), np.float64(0.4979964015723823)], [np.float64(0.48644860286824587), np.float64(0.4993284669745627)], [np.float64(0.48868754052483676), np.float64(0.49868622209437263)], [np.float64(0.49022023491652433), np.float64(0.4996116997904052)], [np.float64(0.49000633790901554), np.float64(0.49999999999999994)], [np.float64(0.4899119360112812), np.float64(0.4999999999999999)], [np.float64(0.48852608508432527), np.float64(0.4995634211913889)], [np.int64(0), np.int64(0)], [np.float64(0.4874929208384095), np.float64(0.49960096973061213)], [np.float64(0.4875024182611544), np.float64(0.49968577021276456)], [np.float64(0.4731507627560527), np.float64(0.4941653486029174)], [np.float64(0.4879734346572432), np.float64(0.49978337351175)], [np.float64(0.4849401823228815), np.float64(0.4995044419138019)], [np.float64(0.48660117105972717), np.float64(0.49890872442109446)], [np.float64(0.49053546007075643), np.float64(0.49999999999999994)], [np.int64(0), np.int64(0)], [np.float64(0.48466805439794236), np.float64(0.4991367455964452)], [np.float64(0.49045104512256166), np.float64(0.49994625732641695)], [np.float64(0.3653604843405711), np.float64(0.011293882208110647)], [np.int64(0), np.int64(0)], [np.float64(0.488703171001413), np.float64(0.49999999999999994)], [np.int64(0), np.int64(0)], [np.float64(0.4806572873634744), np.float64(0.49578928703425057)], [np.float64(0.4866719153096777), np.float64(0.4984020301233571)], [np.int64(0), np.int64(0)], [np.float64(0.4890241257575117), np.float64(0.49999999999999983)], [np.float64(0.4812230877452701), np.float64(0.49910691926005973)], [np.float64(0.4885758967810348), np.float64(0.4997394545021743)]]]}}}