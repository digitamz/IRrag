{'sample_level_eval_list': {'claim_check_methods_0_truth_method_0': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}, 'claim_check_methods_0_truth_method_1': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}}, 'dataset_level_eval_list': {'claim_check_methods_0_truth_method_0': {'prr': np.float64(0.6118587143378161)}, 'claim_check_methods_0_truth_method_1': {'prr': np.float64(0.6118587143378161)}}, 'output_dict': {'previous_context': [{'role': 'system', 'content': 'You are a helpful assistant. Give precise answers.'}], 'user_prompt': 'Context: {context}\nQuestion: {question}', 'generation': ['**Joey D. Vieira: Bio**\n\n**Full Name:** Joseph Douglas Vieira  \n**Professional Name:** Joey D. Vieira  \n**Born:** April 8, 1944  \n**Nationality:** American  \n\n**Early Career:**\nJoey D. Vieira began his acting career as a child actor under the professional name Donald Keeler. He played the role of Sylvester "Porky" Brockway, a chubby, beanie-wearing farm boy, in the first several seasons (1954–57) of the popular television series "Lassie," which was later retitled "Jeff\'s Collie" in syndicated reruns and on DVD. The show won two Emmy Awards during his run, and Vieira, along with co-star Tommy Rettig, jointly accepted the show\'s second Emmy.\n\n**Family Connections:**\nVieira borrowed his professional surname, Keeler, from his aunt, Ruby Keeler, a star of numerous Warner Bros. musicals in the 1930s. He is also the half-brother of Ken Weatherwax, who is best known for portraying Pugsley Addams on the 1960s television sitcom "The Addams Family."\n\n**Film and Television Appearances:**\nThroughout his career, Vieira has appeared in various films and television shows. Notable appearances include:\n- "The Private War of Major Benson" (1955) with Charlton Heston\n- "The Patriot" (2000) with Mel Gibson, where he played the role of Peter Howard\n\n**Other Ventures:**\nVieira is not limited to acting. He has also ventured into writing, producing, and directing. Additionally, he had a music career in the 1970s and 1980s. One of his R&B ballads was sampled by Tyler The Creator in the song "911/Mr. Lonely" on the album "Flower Boy."\n\n**Summary:**\nJoey D. Vieira is a versatile American actor with a career spanning multiple decades, starting as a child actor and evolving into roles in both film and television. His family connections to Hollywood and his diverse talents in acting, writing, producing, directing, and music have made him a notable figure in the entertainment industry.'], 'claims': [['Joey D. Vieira is the subject of the bio.', 'Joey D. Vieira has a bio that outlines his life and achievements.', 'Joseph Douglas Vieira is the full name of the person mentioned.', 'Joey D. Vieira is the professional name.', 'The person was born on April 8, 1944.', "The person's nationality is American.", 'Joey D. Vieira began his acting career as a child actor under the professional name Donald Keeler.', "Joey D. Vieira played the role of Sylvester 'Porky' Brockway in the first several seasons (1954–57) of the popular television series 'Lassie.'", "Sylvester 'Porky' Brockway was a chubby, beanie-wearing farm boy.", "The television series 'Lassie' was later retitled 'Jeff's Collie' in syndicated reruns and on DVD.", "The show 'Lassie' won two Emmy Awards during Joey D. Vieira's run.", "Joey D. Vieira, along with co-star Tommy Rettig, jointly accepted the show's second Emmy.", 'Vieira borrowed his professional surname, Keeler, from his aunt, Ruby Keeler.', 'Ruby Keeler was a star of numerous Warner Bros. musicals in the 1930s.', 'Vieira is the half-brother of Ken Weatherwax.', "Ken Weatherwax is best known for portraying Pugsley Addams on the 1960s television sitcom 'The Addams Family.'", 'Vieira has appeared in various films and television shows.', 'The Private War of Major Benson was released in 1955.', 'Charlton Heston starred in The Private War of Major Benson.', 'The Patriot is a movie from 2000.', 'Mel Gibson starred in The Patriot.', 'Mel Gibson played the role of Peter Howard in The Patriot.', 'Vieira has ventured into writing, producing, and directing.', 'Vieira had a music career in the 1970s and 1980s.', "One of Vieira's R&B ballads was sampled by Tyler The Creator in the song '911/Mr. Lonely' on the album 'Flower Boy.'", 'Joey D. Vieira is a versatile American actor.', 'Joey D. Vieira has a career spanning multiple decades.', 'Joey D. Vieira started his career as a child actor.', 'Joey D. Vieira has roles in both film and television.', 'Joey D. Vieira has family connections to Hollywood.', 'Joey D. Vieira has diverse talents in acting, writing, producing, directing, and music.', 'Joey D. Vieira is a notable figure in the entertainment industry.']], 'claim_correctness': [array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1])], 'question_text': ['Tell me a bio of Joey D. Vieira.'], 'context': ['{\n  "id" : "19939301",\n  "contents" : "\\"Joey D. Vieira\\"\\nJoey D. Vieira Joseph Douglas Vieira, known as Joey D. Vieira (born April 8, 1944), is an American film and television actor. He began as a child actor using the professional name Donald Keeler playing chubby, beanie-wearing farm boy, Sylvester \\"\\"Porky\\"\\" Brockway in the first several seasons (1954–57) of TV\'s \\"\\"Lassie\\"\\" (retitled \\"\\"Jeff\'s Collie\\"\\" in syndicated reruns and on DVD). Vieira borrowed the professional surname from his aunt, Ruby Keeler, star of numerous Warner Bros. musicals in the 1930s. \\"\\"Lassie\\"\\" won two Emmys during his run on the series. Vieira and costar Tommy Rettig jointly accepted the show\'s second Emmy"\n}\n{\n  "id" : "19939303",\n  "contents" : "\\"Joey D. Vieira\\"\\nappearances include \\"\\"The Private War of Major Benson\\"\\" (1955) with Charlton Heston and \\"\\"The Patriot\\"\\" (2000) with Mel Gibson in which he played as Peter Howard. Vieira has also written, produced and directed. He also had a music career in the 1970s and 1980s. One of his songs R&B Ballad was sampled by the Tyler The Creator song 911/Mr.Lonely on his album Flower Boy. In addition to being the nephew of Ruby Keeler, he was the half-brother of actor Ken Weatherwax (now deceased), best known for portraying Pugsley Addams on the 1960s television sitcom \\"\\"The Addams Family\\"\\". Joey D. Vieira"\n}\n{\n  "id" : "15002362",\n  "contents" : "\\"Angélico Vieira\\"\\nAngélico Vieira Angélico Vieira (December 31, 1982 – June 28, 2011), whose full name was Sandro Milton Vieira Angélico, was a Portuguese actor and singer. He was a former member of the Portuguese boy band, D\'ZRT. Vieira began his career when he was cast as the character, David, in the Portuguese soap opera, \\"\\"Morangos com Açúcar\\"\\". Simultaneously, he joined the boy band, D\'ZRT, which achieved national attention. Vieira appeared in several other television roles, including soap operas, during his career. In the early morning hours of June 25, 2011, Vieira was driving from northern Portugal to Lisbon for the release"\n}'], 'claim_check_methods': ['QuestionAnswerGeneration'], 'claim_check_methods_0': {'name': 'Claim Check Method by Generating Questions and Answers.\nQuestion generation model: openrouter/qwen/qwen-2.5-72b-instruct\nNumber of questions to be generated for a stament: 2\nNumber of trials to generate an answer that entails with the claim: 2\nEntailment check model: <class \'transformers.models.deberta.modeling_deberta.DebertaForSequenceClassification\'>\n\nQuestion generation instruction for the first claim:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nQuestion generation instruction for claims with preceeding text:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nAnswer generation instruction:\n    [{\'role\': \'system\', \'content\': \'You are a helpful assistant. Give a single claim answer to given question. Don\\\\‘t provide any additional information. Just answer the question with a brief sentence in a single claim.\'}, {\'role\': \'user\', \'content\': \'{question}\'}]\n\nTruth methods to assign a score the question(s):\n   [<TruthTorchLM.truth_methods.matrix_degree_uncertainty.MatrixDegreeUncertainty object at 0x000002513AEF4BE0>, <TruthTorchLM.truth_methods.eccentricity_uncertainty.EccentricityUncertainty object at 0x000002513B109480>]', 'truth_methods': ['MatrixDegreeUncertainty', 'EccentricityUncertainty'], 'truth_methods_name': ['MatrixDegreeUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x000002513B0B3F10>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'temperature\': 3.0, \'batch_generation\': True}', 'EccentricityUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x000002513B11A6B0>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'eigen_threshold\': 0.9, \'temperature\': 3.0, \'batch_generation\': True}'], 'truth_values': [[[np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.38078434944152834), np.float64(-2.187809004514335)], [np.float64(-0.25145825624465945), np.float64(-3.0786018721674564)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.040209197998046876), np.float64(-1.6653345369377348e-16)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.3113821458816528), np.float64(-2.9432129611273545)], [np.float64(-0.276755166053772), np.float64(-1.7886613237691158)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.6316734194755554), np.float64(-3.778726688010079)], [np.float64(-0.039558486938476564), np.float64(-0.002036577037347831)], [np.float64(-0.4745202565193176), np.float64(-4.472135954999579)], [np.float64(-0.04095144271850586), np.float64(-2.220446049250313e-16)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.041507210731506344), np.float64(-2.4698973350056885e-05)], [np.float64(-0.04027719497680664), np.float64(-5.551115123125783e-17)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.2694622802734375), np.float64(-1.7888543819998317)], [np.float64(-0.4227577257156372), np.float64(-2.8850008325868988)], [np.float64(-0.5031587266921997), np.float64(-4.47213595499958)], [np.float64(-0.37256454467773437), np.float64(-2.909056163444193)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.1746048617362976), np.float64(-1.7864321728059802)], [np.float64(-0.2584147143363953), np.float64(-1.7018507917247163)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.6021523427963257), np.float64(-3.778726688010081)]]], 'normalized_truth_values': [[[np.int64(0), np.int64(0)], [np.float64(0.4059377354553597), np.float64(0.10085059882001948)], [np.float64(0.43746460515527913), np.float64(0.04399858696425014)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.4899490546442869), np.float64(0.49999999999999994)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.4227774086371008), np.float64(0.050058267996484586)], [np.float64(0.4312494691954491), np.float64(0.14323692752777692)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.34713119191137715), np.float64(0.022341233601662867)], [np.float64(0.4901116677311647), np.float64(0.49949085591664216)], [np.float64(0.3835469190550832), np.float64(0.011293882208110647)], [np.float64(0.4897635698391299), np.float64(0.49999999999999994)], [np.int64(0), np.int64(0)], [np.float64(0.4896246868654457), np.float64(0.4999938252566628)], [np.float64(0.48993206228037356), np.float64(0.5)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.4330391092029948), np.float64(0.14321323703222513)], [np.float64(0.39585703927796995), np.float64(0.05290002569114446)], [np.float64(0.3767986439433726), np.float64(0.011293882208110636)], [np.float64(0.40792148281214197), np.float64(0.05170769598041249)], [np.int64(0), np.int64(0)], [np.float64(0.45645934654236375), np.float64(0.1435107067969114)], [np.float64(0.43575344638049207), np.float64(0.15422369560358715)], [np.int64(0), np.int64(0)], [np.float64(0.3538514261794078), np.float64(0.022341233601662822)]]]}}}