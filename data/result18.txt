{'sample_level_eval_list': {'claim_check_methods_0_truth_method_0': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}, 'claim_check_methods_0_truth_method_1': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}}, 'dataset_level_eval_list': {'claim_check_methods_0_truth_method_0': {'prr': np.float64(-0.7549508160826648)}, 'claim_check_methods_0_truth_method_1': {'prr': np.float64(-0.30699071231347685)}}, 'output_dict': {'previous_context': [{'role': 'system', 'content': 'You are a helpful assistant. Give precise answers.'}], 'user_prompt': 'Context: {context}\nQuestion: {question}', 'generation': ['Iggy Azalea, born Amethyst Amelia Kelly on June 7, 1990, is an Australian rapper, singer, songwriter, model, and television personality. She grew up in Mullumbimby, New South Wales, Australia. Her father, Brendan Kelly, was a European-Australian painter and comic artist, while her mother, Tanya, worked as a cleaner for holiday houses and hotels. Azalea lived in a house her father built by hand from mud bricks, located on a large piece of land. She claims to have some Aboriginal ancestry, stating that her family has been in Australia for over 100 years.\n\nAt the age of 16, Azalea moved to the United States to pursue a career in music. Her stage name, "Iggy Azalea," is derived from the name of her childhood dog and the street she lived on, which she chose to sound more masculine and unique. She gained public recognition after releasing music videos for her songs "Pu$$y" and "Two Times" on YouTube. In 2012, she signed a recording contract with Grand Hustle Records, owned by T.I.\n\nAzalea\'s breakthrough came with her debut studio album, "The New Classic," released in 2014, which included the hit single "Fancy" featuring Charli XCX. The song became her first number-one hit in the United States and earned her a Grammy nomination. Her success continued with her 2016 mixtape, "Savage X Fenty."\n\nThroughout her career, Azalea has received numerous accolades, including being named one of the 9th Annual Billboard Women in Music honorees as a chart-topper, topping the Billboard Year-End\'s Top New Artists chart in 2014, and receiving the Woman of the Year award from GQ Australia in 2016. She has also been nominated for multiple Billboard Music Awards and iHeartRadio Music Awards.\n\nIn addition to her music, Azalea has ventured into modeling and television, participating in various fashion campaigns and reality TV shows. She is known for her distinctive style and bold personality, making her a prominent figure in the music and entertainment industry.'], 'claims': [['Iggy Azalea, born Amethyst Amelia Kelly on June 7, 1990, is an Australian rapper, singer, songwriter, model, and television personality.', 'Iggy Azalea grew up in Mullumbimby, New South Wales, Australia.', "Iggy Azalea's father, Brendan Kelly, was a European-Australian painter and comic artist.", "Iggy Azalea's mother, Tanya, worked as a cleaner for holiday houses and hotels.", 'Iggy Azalea lived in a house her father built by hand from mud bricks, located on a large piece of land.', 'Iggy Azalea claims to have some Aboriginal ancestry.', "Iggy Azalea's family has been in Australia for over 100 years.", 'At the age of 16, Azalea moved to the United States to pursue a career in music.', "Azalea's stage name, 'Iggy Azalea,' is derived from the name of her childhood dog and the street she lived on.", 'Azalea chose her stage name to sound more masculine and unique.', "Azalea gained public recognition after releasing music videos for her songs 'Pu$$y' and 'Two Times' on YouTube.", 'In 2012, Azalea signed a recording contract with Grand Hustle Records.', 'Grand Hustle Records is owned by T.I.', "Azalea's breakthrough came with her debut studio album, 'The New Classic,' released in 2014.", "Azalea's debut studio album, 'The New Classic,' included the hit single 'Fancy' featuring Charli XCX.", "The song 'Fancy' became Azalea's first number-one hit in the United States.", "The song 'Fancy' earned Azalea a Grammy nomination.", "Azalea's success continued with her 2016 mixtape, 'Savage X Fenty.'", 'Azalea has received numerous accolades throughout her career.', 'Azalea was named one of the 9th Annual Billboard Women in Music honorees as a chart-topper.', "Azalea topped the Billboard Year-End's Top New Artists chart in 2014.", 'Azalea received the Woman of the Year award from GQ Australia in 2016.', 'Azalea has been nominated for multiple Billboard Music Awards.', 'Azalea has been nominated for multiple iHeartRadio Music Awards.', 'Azalea has ventured into modeling and television.', 'Azalea has participated in various fashion campaigns.', 'Azalea has participated in reality TV shows.', 'Azalea is known for her distinctive style.', 'Azalea is known for her bold personality.', 'Azalea is a prominent figure in the music and entertainment industry.']], 'claim_correctness': [array([ 1,  0,  1,  1,  1, -1,  1,  1,  1,  0,  1,  1,  0,  0,  0,  0,  0,
        0,  1,  1,  1,  1,  1,  1,  1,  0,  0,  0,  1,  1])], 'question_text': ['Tell me a bio of Iggy Azalea.'], 'context': ['{\n  "id" : "8169212",\n  "contents" : "\\"Iggy Azalea\\"\\nIggy Azalea Amethyst Amelia Kelly (born 7 June 1990), known professionally as Iggy Azalea (), is an Australian rapper, singer, songwriter, model and television personality. Azalea moved to the United States at the age of 16 to pursue a career in music, and has since resided in Los Angeles. Her stage name, from the masculine \\"\\"Egnatius\\"\\", comes from the name of her dog and the street she lived on. She earned public recognition after releasing music videos for her songs \\"\\"Pu$$y\\"\\" and \\"\\"Two Times\\"\\" on YouTube. In 2012 Azalea signed a recording contract with Grand Hustle Records, which is owned"\n}\n{\n  "id" : "7375315",\n  "contents" : "\\"Iggy Azalea\\"\\nNew South Wales. Her father, Brendan Kelly, was a European-Australian painter and comic artist, while her mother, Tanya, cleaned holiday houses and hotels. Azalea lived in a house that her father built by hand from mud-bricks, surrounded by of land. According to Azalea, she has some Aboriginal (Indigenous Australian) ancestry: \\"\\"My family came to Australia on the First Fleet. My family\'s been in that country for a long time, over 100 years. If your family\'s lived in Australia for a long time, everyone has a little bit of [Aborigine blood]. I know my family does because we have an eye"\n}\n{\n  "id" : "8169262",\n  "contents" : "\\"Iggy Azalea\\"\\nof the 9th Annual \\"\\"Billboard\\"\\" Women in Music honorees as a chart-topper. In late 2014, it was announced she was placed at number-one on \\"\\"Billboard\\"\\" Year-End\'s Top New Artists chart. In 2015, Azalea also led the 2015 iHeartRadio Music Awards nominations with five. She received twelve nominations at the 2015 \\"\\"Billboard\\"\\" Music Awards. In 2016, Azalea was presented with the Woman of the Year award by GQ Australia. Iggy Azalea Amethyst Amelia Kelly (born 7 June 1990), known professionally as Iggy Azalea (), is an Australian rapper, singer, songwriter, model and television personality. Azalea moved to the United States at"\n}'], 'claim_check_methods': ['QuestionAnswerGeneration'], 'claim_check_methods_0': {'name': 'Claim Check Method by Generating Questions and Answers.\nQuestion generation model: openrouter/qwen/qwen-2.5-72b-instruct\nNumber of questions to be generated for a stament: 2\nNumber of trials to generate an answer that entails with the claim: 2\nEntailment check model: <class \'transformers.models.deberta.modeling_deberta.DebertaForSequenceClassification\'>\n\nQuestion generation instruction for the first claim:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nQuestion generation instruction for claims with preceeding text:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nAnswer generation instruction:\n    [{\'role\': \'system\', \'content\': \'You are a helpful assistant. Give a single claim answer to given question. Don\\\\â€˜t provide any additional information. Just answer the question with a brief sentence in a single claim.\'}, {\'role\': \'user\', \'content\': \'{question}\'}]\n\nTruth methods to assign a score the question(s):\n   [<TruthTorchLM.truth_methods.matrix_degree_uncertainty.MatrixDegreeUncertainty object at 0x000002522171FE20>, <TruthTorchLM.truth_methods.eccentricity_uncertainty.EccentricityUncertainty object at 0x00000251DB70BEE0>]', 'truth_methods': ['MatrixDegreeUncertainty', 'EccentricityUncertainty'], 'truth_methods_name': ['MatrixDegreeUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x000002522171FF10>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'temperature\': 3.0, \'batch_generation\': True}', 'EccentricityUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x000002522176D300>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'eigen_threshold\': 0.9, \'temperature\': 3.0, \'batch_generation\': True}'], 'truth_values': [[[np.float64(-0.4175981283187866), np.float64(-2.190752986952211)], [np.float64(-0.040204095840454104), np.float64(-5.551115123125783e-17)], [np.float64(-0.6127545428276062), np.float64(-3.779329585641505)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.04066200256347656), np.float64(-3.885780586188048e-16)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.06816500425338745), np.float64(-0.022312088755384984)], [np.float64(-0.25921682596206663), np.float64(-3.0736104806320874)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.34040160179138185), np.float64(-2.8964893956996898)], [np.float64(-0.042584991455078124), np.float64(-4.996003610813204e-16)], [np.float64(-0.0493001127243042), np.float64(-0.0025800902952053395)], [np.float64(-0.039309189319610596), np.float64(-0.0005032336654102187)], [np.float64(-0.03919367790222168), np.float64(-2.7755575615628914e-16)], [np.float64(-0.03849804878234863), np.float64(-0.00018512635454048798)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.11381476163864136), np.float64(-2.00312241290841)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.04033594131469727), np.float64(-5.551115123125783e-17)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.05256776809692383), np.float64(-1.6653345369377348e-16)], [np.float64(-0.04932270050048828), np.float64(-2.7755575615628914e-16)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.04289231300354004), np.float64(-5.551115123125783e-16)], [np.float64(-0.2084632110595703), np.float64(-2.819901395105392)], [np.float64(-0.09317734479904174), np.float64(-0.018123934802145858)], [np.float64(-0.04182677745819092), np.float64(-0.00042609495394846375)], [np.float64(-0.05554099559783936), np.float64(-0.00432495222171958)]]], 'normalized_truth_values': [[[np.float64(0.3970916395473337), np.float64(0.10058395273766373)], [np.float64(0.4899503296683228), np.float64(0.5)], [np.float64(0.35143110581198583), np.float64(0.022328068841147256)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.48983589976284114), np.float64(0.4999999999999999)], [np.int64(0), np.int64(0)], [np.float64(0.4829653443408385), np.float64(0.49442220920820973)], [np.float64(0.43555623945900274), np.float64(0.04420901694435155)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.4157119264875761), np.float64(0.05232737787323509)], [np.float64(0.4893553607423064), np.float64(0.4999999999999999)], [np.float64(0.48767746754523345), np.float64(0.4993549777840175)], [np.float64(0.4901739679130365), np.float64(0.4998741915863025)], [np.float64(0.49020283464738384), np.float64(0.49999999999999994)], [np.float64(0.49037667633552895), np.float64(0.49995371841149705)], [np.int64(0), np.int64(0)], [np.float64(0.4715769851389508), np.float64(0.11887547829424944)], [np.int64(0), np.int64(0)], [np.float64(0.48991738165931487), np.float64(0.5)], [np.int64(0), np.int64(0)], [np.float64(0.4868610834773405), np.float64(0.49999999999999994)], [np.float64(0.487671824032595), np.float64(0.49999999999999994)], [np.int64(0), np.int64(0)], [np.float64(0.4892785654291139), np.float64(0.49999999999999983)], [np.float64(0.4480721132996248), np.float64(0.05625816859221859)], [np.float64(0.4767225026672308), np.float64(0.49546914032238887)], [np.float64(0.4895448298496671), np.float64(0.4998934762631246)], [np.float64(0.4861183194369698), np.float64(0.49891876362996584)]]]}}}