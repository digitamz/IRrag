{'sample_level_eval_list': {'claim_check_methods_0_truth_method_0': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}, 'claim_check_methods_0_truth_method_1': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}}, 'dataset_level_eval_list': {'claim_check_methods_0_truth_method_0': {'prr': np.float64(0.47349979138806964)}, 'claim_check_methods_0_truth_method_1': {'prr': np.float64(0.5357949228899869)}}, 'output_dict': {'previous_context': [{'role': 'system', 'content': 'You are a helpful assistant. Give precise answers.'}], 'user_prompt': 'Context: {context}\nQuestion: {question}', 'generation': ["Tim Fischer, AC (born 3 May 1946) is a former Australian politician and diplomat. Here is his biography:\n\n### Early Life and Background\n- **Birth and Origin**: Born on 3 May 1946 in Lockhart, New South Wales, Australia.\n- **Education and Early Career**: Served with the Australian Army in the Vietnam War. Upon returning, he purchased a farming property at Boree Creek.\n\n### Political Career\n- **State Politics**: Served in the New South Wales Legislative Assembly from 1971 to 1984.\n- **Federal Politics**: Elected to the House of Representatives in 1984, representing the Division of Farrer.\n- **National Party Leadership**: Became the leader of the National Party of Australia from 1990 to 1999.\n- **Deputy Prime Minister**: Served as Deputy Prime Minister in the Liberal-National Coalition government led by John Howard from 1996 to 1999.\n\n### Post-Political Career\n- **Diplomatic Role**: Appointed as Australian Ambassador to the Holy See (Vatican) in 2006. He played a significant role in the canonization of Australia's first Roman Catholic saint, Mary MacKillop.\n- **Retirement**: Retired from his diplomatic post on 20 January 2012.\n\n### Controversies and Advocacy\n- **Gun Control**: In August 2013, following the shooting death of Australian baseball player Christopher Lane in Oklahoma, Fischer called for a tourism boycott of the United States to protest the activities of the National Rifle Association and what he felt were overly lax American gun laws.\n\n### Personal Life\n- **Family**: No specific details provided in the given context, but Fischer is known to have been married and has children.\n\n### Legacy\n- **Political Influence**: Fischer is remembered for his significant contributions to Australian politics, particularly during his tenure as Deputy Prime Minister. He was a key figure in the Howard Government and played a pivotal role in several major policy initiatives and reforms.\n\nThis biography covers the key aspects of Tim Fischer's life, from his early career in farming and the military to his influential roles in Australian politics and diplomacy."], 'claims': [['Tim Fischer, AC was born on 3 May 1946.', 'Tim Fischer, AC is a former Australian politician.', 'Tim Fischer, AC is a former Australian diplomat.', 'The individual was born on 3 May 1946.', 'The individual was born in Lockhart, New South Wales, Australia.', 'He served with the Australian Army in the Vietnam War.', 'Upon returning, he purchased a farming property at Boree Creek.', 'The individual served in the New South Wales Legislative Assembly from 1971 to 1984.', 'The individual was elected to the House of Representatives in 1984.', 'The individual represents the Division of Farrer.', 'The individual became the leader of the National Party of Australia from 1990 to 1999.', 'The individual served as Deputy Prime Minister in the Liberal-National Coalition government.', 'The government was led by John Howard from 1996 to 1999.', 'The person was appointed as the Australian Ambassador to the Holy See (Vatican) in 2006.', "The person played a significant role in the canonization of Australia's first Roman Catholic saint, Mary MacKillop.", 'He retired from his diplomatic post on 20 January 2012.', 'In August 2013, Australian baseball player Christopher Lane was shot and killed in Oklahoma.', 'Fischer called for a tourism boycott of the United States in August 2013.', "Fischer's boycott was to protest the activities of the National Rifle Association.", "Fischer's boycott was to protest what he felt were overly lax American gun laws.", "The paragraph is titled 'Personal Life'.", 'Fischer is known to have been married.', 'Fischer has children.', 'Fischer is remembered for his significant contributions to Australian politics.', 'Fischer served as Deputy Prime Minister during his tenure.', 'Fischer was a key figure in the Howard Government.', 'Fischer played a pivotal role in several major policy initiatives and reforms.', "This biography covers the key aspects of Tim Fischer's life.", 'Tim Fischer had an early career in farming.', 'Tim Fischer had an early career in the military.', 'Tim Fischer had influential roles in Australian politics.', 'Tim Fischer had influential roles in Australian diplomacy.']], 'claim_correctness': [array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 1, 1, 1, 0, 1, 1, 1, 1, 1])], 'question_text': ['Tell me a bio of Tim Fischer.'], 'context': ['{\n  "id" : "4083596",\n  "contents" : "\\"Tim Fischer\\"\\nTim Fischer Timothy Andrew Fischer, AC (born 3 May 1946), is a former Australian politician and diplomat who served as leader of the National Party from 1990 to 1999. He was Deputy Prime Minister in the Howard Government from 1996 to 1999. Fischer was born in Lockhart, New South Wales. He served with the Australian Army in the Vietnam War, and on his return bought a farming property at Boree Creek. He served in the New South Wales Legislative Assembly from 1971 to 1984. Fisher was elected to the House of Representatives at the 1984 election, representing the Division of"\n}\n{\n  "id" : "16238114",\n  "contents" : "\\"Tim Fischer (wrestler)\\"\\nTim Fischer (wrestler) Timothy \\"\\"Tim\\"\\" Frank Fisher (born November 7, 1967) is an American musician, comedian, writer and professional wrestler, known by his ring name \\"\\"The Real Deal\\"\\" Damien Steele. Fisher competed in WWE, WCW, XPW, WWC and UPW between 1995-2007. Fisher held the XPW World Heavyweight Championship on two occasions. Fisher debuted in August 1995 and spent much of his early career wrestling on the local independent circuit in southern California under the name Nick Beat. He became a regular for the United Independent Wrestling Alliance and Southern California Championship Wrestling as well as toured the Eastern United States"\n}\n{\n  "id" : "4083607",\n  "contents" : "\\"Tim Fischer\\"\\nof the canonisation of Australia\'s first Roman Catholic saint, Mary MacKillop. He retired from the post on 20 January 2012. In August 2013, following the shooting death of Australian baseball player Christopher Lane in Oklahoma, Fischer called for a tourism boycott of the United States to protest the activities of the National Rifle Association and what he felt were overly lax American gun laws. In 2014 it was revealed in the ABC programme A Country Road: The Nationals that sometime before the 1998 Federal election, Fischer, then National Party leader met with his deputy John Anderson and former minister John"\n}'], 'claim_check_methods': ['QuestionAnswerGeneration'], 'claim_check_methods_0': {'name': 'Claim Check Method by Generating Questions and Answers.\nQuestion generation model: openrouter/qwen/qwen-2.5-72b-instruct\nNumber of questions to be generated for a stament: 2\nNumber of trials to generate an answer that entails with the claim: 2\nEntailment check model: <class \'transformers.models.deberta.modeling_deberta.DebertaForSequenceClassification\'>\n\nQuestion generation instruction for the first claim:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nQuestion generation instruction for claims with preceeding text:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nAnswer generation instruction:\n    [{\'role\': \'system\', \'content\': \'You are a helpful assistant. Give a single claim answer to given question. Don\\\\â€˜t provide any additional information. Just answer the question with a brief sentence in a single claim.\'}, {\'role\': \'user\', \'content\': \'{question}\'}]\n\nTruth methods to assign a score the question(s):\n   [<TruthTorchLM.truth_methods.matrix_degree_uncertainty.MatrixDegreeUncertainty object at 0x000001F33657FCD0>, <TruthTorchLM.truth_methods.eccentricity_uncertainty.EccentricityUncertainty object at 0x000001F3463643D0>]', 'truth_methods': ['MatrixDegreeUncertainty', 'EccentricityUncertainty'], 'truth_methods_name': ['MatrixDegreeUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x000001F346364820>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'temperature\': 3.0, \'batch_generation\': True}', 'EccentricityUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x000001F346364160>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'eigen_threshold\': 0.9, \'temperature\': 3.0, \'batch_generation\': True}'], 'truth_values': [[[np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.07730669498443604), np.float64(-0.008207369646666074)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.6885281586647034), np.float64(-4.4721359549995805)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.05435271263122558), np.float64(-2.7755575615628914e-16)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.07276153564453125), np.float64(-0.004770259819022515)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.06680743217468262), np.float64(-0.015106671237972935)], [np.float64(-0.09297529220581055), np.float64(-0.00698900175912287)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.0663077449798584), np.float64(-0.01937450871800106)], [np.float64(-0.05717748165130615), np.float64(-0.005223238550320086)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.22942627668380738), np.float64(-1.9404213147444898)], [np.float64(-0.20998139381408693), np.float64(-1.7888543819998317)], [np.float64(-0.06110995292663574), np.float64(-0.0032989872706541967)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.6034281396865845), np.float64(-3.77872668801008)], [np.float64(-0.0691591739654541), np.float64(-0.014858712992584455)], [np.float64(-0.06908170223236083), np.float64(-0.005090149959060208)], [np.float64(-0.05485048294067383), np.float64(-2.220446049250313e-16)], [np.float64(-0.09017600297927857), np.float64(-0.004697681468407822)], [np.float64(-0.2775670886039734), np.float64(-2.880799232181721)], [np.float64(-0.1048045039176941), np.float64(-0.014643335935648705)], [np.float64(-0.12616250276565552), np.float64(-1.6479325796527218)], [np.float64(-0.20054168462753297), np.float64(-2.0510118538412416)], [np.float64(-0.04495420932769775), np.float64(-0.002512866013441306)], [np.float64(-0.0543240213394165), np.float64(-0.0081845887965315)]]], 'normalized_truth_values': [[[np.int64(0), np.int64(0)], [np.float64(0.4806829457121312), np.float64(0.497948169106088)], [np.int64(0), np.int64(0)], [np.float64(0.33436057162303784), np.float64(0.011293882208110628)], [np.int64(0), np.int64(0)], [np.float64(0.4864151660569055), np.float64(0.49999999999999994)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.4818176371987892), np.float64(0.4988074373066782)], [np.int64(0), np.int64(0)], [np.float64(0.48330435120866655), np.float64(0.49622340401212484)], [np.float64(0.4767729065718733), np.float64(0.49825275667238866)], [np.int64(0), np.int64(0)], [np.float64(0.48342913476064425), np.float64(0.4951565243281481)], [np.float64(0.485709522654134), np.float64(0.49869419333119414)], [np.int64(0), np.int64(0)], [np.float64(0.4428937006028146), np.float64(0.1256015779781129)], [np.float64(0.4476966910679213), np.float64(0.14321323703222513)], [np.float64(0.48472726438140096), np.float64(0.4991752539303341)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.35355978163852564), np.float64(0.022341233601662853)], [np.float64(0.48271709462512524), np.float64(0.4962853900946521)], [np.float64(0.48273643944357525), np.float64(0.49872746525780876)], [np.float64(0.48629081618535297), np.float64(0.49999999999999994)], [np.float64(0.4774712636186283), np.float64(0.498825581792673)], [np.float64(0.4310503373463366), np.float64(0.05311092852669812)], [np.float64(0.4738228304363671), np.float64(0.4963392314299102)], [np.float64(0.4685011437768935), np.float64(0.16138856314708674)], [np.float64(0.450031930387492), np.float64(0.11395017900050645)], [np.float64(0.4887633399336854), np.float64(0.49937178382721203)], [np.float64(0.4864223335877387), np.float64(0.49795386422298)]]]}}}