{'sample_level_eval_list': {'claim_check_methods_0_truth_method_0': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}, 'claim_check_methods_0_truth_method_1': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}}, 'dataset_level_eval_list': {'claim_check_methods_0_truth_method_0': {'prr': np.float64(0.03172897724814307)}, 'claim_check_methods_0_truth_method_1': {'prr': np.float64(0.24751862538689298)}}, 'output_dict': {'previous_context': [{'role': 'system', 'content': 'You are a helpful assistant. Give precise answers.'}], 'user_prompt': 'Context: {context}\nQuestion: {question}', 'generation': ['Heinrich Harrer (6 July 1912 – 7 January 2006) was an Austrian mountaineer, sportsman, geographer, and author. Born in Hüttenberg, Austria, in the district of Sankt Veit an der Glan in the state of Carinthia, his father was a postal worker. Harrer studied geography and sports from 1933 to 1938.\n\nHe is best known for his achievements in mountaineering and his literary works. In 1938, he was part of the four-man climbing team that made the first successful ascent of the North Face of the Eiger in Switzerland, a feat that earned him international recognition.\n\nHarrer gained further prominence with the publication of his memoir "Seven Years in Tibet" (1952), which detailed his experiences in Tibet during the 1940s. The book provided a unique perspective on Tibetan culture and society, and it was later adapted into a film directed by Jean-Jacques Annaud in 1997, starring Brad Pitt.\n\nAnother notable work by Harrer is "The White Spider" (1959), which is a detailed account of the Eiger North Face climb and its historical context. This book is considered a classic in mountaineering literature.\n\nIn October 2002, the Dalai Lama presented Harrer with the International Campaign for Tibet\'s Light of Truth Award, recognizing his efforts to bring international attention to the situation in Tibet.\n\nHeinrich Harrer passed away on 7 January 2006 in Friesach, Austria, at the age of 93, leaving behind a legacy as an adventurer, writer, and advocate for Tibetan causes.'], 'claims': [['Heinrich Harrer was born on 6 July 1912.', 'Heinrich Harrer died on 7 January 2006.', 'Heinrich Harrer was an Austrian mountaineer, sportsman, geographer, and author.', 'Heinrich Harrer was born in Hüttenberg, Austria.', 'Hüttenberg is in the district of Sankt Veit an der Glan in the state of Carinthia.', "Heinrich Harrer's father was a postal worker.", 'Heinrich Harrer studied geography and sports from 1933 to 1938.', 'He is best known for his achievements in mountaineering.', 'He is best known for his literary works.', 'In 1938, he was part of the four-man climbing team.', 'The four-man climbing team made the first successful ascent of the North Face of the Eiger in Switzerland.', 'The first successful ascent of the North Face of the Eiger in Switzerland earned him international recognition.', "Harrer gained further prominence with the publication of his memoir 'Seven Years in Tibet' in 1952.", "'Seven Years in Tibet' detailed Harrer's experiences in Tibet during the 1940s.", "'Seven Years in Tibet' provided a unique perspective on Tibetan culture and society.", "'Seven Years in Tibet' was adapted into a film directed by Jean-Jacques Annaud in 1997.", "The film adaptation of 'Seven Years in Tibet' starred Brad Pitt.", "Harrer wrote 'The White Spider' in 1959.", "'The White Spider' is a detailed account of the Eiger North Face climb.", "'The White Spider' provides historical context of the Eiger North Face climb.", "'The White Spider' is considered a classic in mountaineering literature.", "In October 2002, the Dalai Lama presented Harrer with the International Campaign for Tibet's Light of Truth Award.", "The International Campaign for Tibet's Light of Truth Award recognizes efforts to bring international attention to the situation in Tibet.", 'Heinrich Harrer passed away on 7 January 2006.', 'Heinrich Harrer passed away in Friesach, Austria.', 'Heinrich Harrer was 93 years old when he passed away.', 'Heinrich Harrer was an adventurer.', 'Heinrich Harrer was a writer.', 'Heinrich Harrer was an advocate for Tibetan causes.']], 'claim_correctness': [array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,
       1, 1, 1, 1, 1, 1, 1])], 'question_text': ['Tell me a bio of Heinrich Harrer.'], 'context': ['{\n  "id" : "2625518",\n  "contents" : "\\"Heinrich Harrer\\"\\nHeinrich Harrer Heinrich Harrer (; 6 July 1912 – 7 January 2006) was an Austrian mountaineer, sportsman, geographer, and author. He is best known for being on the four-man climbing team that made the first ascent of the North Face of the Eiger in Switzerland, and for his books \\"\\"Seven Years in Tibet\\"\\" (1952) and \\"\\"The White Spider\\"\\" (1959). Heinrich Harrer was born 6 July 1912 in Hüttenberg, Austria, in the district of Sankt Veit an der Glan in the state of Carinthia. His father was a postal worker. From 1933 to 1938, Harrer studied geography and sports at the"\n}\n{\n  "id" : "19806806",\n  "contents" : "\\"Johann Gottlob Harrer\\"\\nJohann Gottlob Harrer (Johann) Gottlob Harrer (8 May 1703 – 9 July 1755) was a German composer and choir leader. Harrer was born in Görlitz, and studied music in Leipzig and Italy. From 1731 he worked in the chapel-choir of Reichsgraf Heinrich von Brühl, who helped him to the post of Thomaskantor in Leipzig in 1750 on the death of that office\'s previous holder, Johann Sebastian Bach – Harrer held the post until his own death in 1755. He composed much instrumental music, including 27 symphonies, 24 orchestral suites, 51 flute duets and a number of harpsichord sonatas. He also"\n}\n{\n  "id" : "2625527",\n  "contents" : "\\"Heinrich Harrer\\"\\nOctober 2002, the Dalai Lama presented Harrer with the International Campaign for Tibet\'s Light of Truth Award for his efforts to bring the situation in Tibet to international attention. Harrer died on 7 January 2006 in Friesach, Austria at the age of 93. Heinrich Harrer Heinrich Harrer (; 6 July 1912 – 7 January 2006) was an Austrian mountaineer, sportsman, geographer, and author. He is best known for being on the four-man climbing team that made the first ascent of the North Face of the Eiger in Switzerland, and for his books \\"\\"Seven Years in Tibet\\"\\" (1952) and \\"\\"The White"\n}'], 'claim_check_methods': ['QuestionAnswerGeneration'], 'claim_check_methods_0': {'name': 'Claim Check Method by Generating Questions and Answers.\nQuestion generation model: openrouter/qwen/qwen-2.5-72b-instruct\nNumber of questions to be generated for a stament: 2\nNumber of trials to generate an answer that entails with the claim: 2\nEntailment check model: <class \'transformers.models.deberta.modeling_deberta.DebertaForSequenceClassification\'>\n\nQuestion generation instruction for the first claim:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nQuestion generation instruction for claims with preceeding text:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nAnswer generation instruction:\n    [{\'role\': \'system\', \'content\': \'You are a helpful assistant. Give a single claim answer to given question. Don\\\\‘t provide any additional information. Just answer the question with a brief sentence in a single claim.\'}, {\'role\': \'user\', \'content\': \'{question}\'}]\n\nTruth methods to assign a score the question(s):\n   [<TruthTorchLM.truth_methods.matrix_degree_uncertainty.MatrixDegreeUncertainty object at 0x0000019208A0E9E0>, <TruthTorchLM.truth_methods.eccentricity_uncertainty.EccentricityUncertainty object at 0x0000019208B59510>]', 'truth_methods': ['MatrixDegreeUncertainty', 'EccentricityUncertainty'], 'truth_methods_name': ['MatrixDegreeUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x0000019208924C70>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'temperature\': 3.0, \'batch_generation\': True}', 'EccentricityUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x0000019208B68CA0>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'eigen_threshold\': 0.9, \'temperature\': 3.0, \'batch_generation\': True}'], 'truth_values': [[[np.float64(-0.04421710968017578), np.float64(-5.551115123125783e-17)], [np.float64(-0.044088888168334964), np.float64(-2.220446049250313e-16)], [np.float64(-0.04045518398284912), np.float64(-0.0006067540100204161)], [np.float64(-0.0402562141418457), np.float64(-6.106226635438361e-16)], [np.float64(-0.040972566604614256), np.float64(-2.7755575615628914e-16)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.15541331291198732), np.float64(-2.010273508023171)], [np.float64(-0.03915948152542114), np.float64(-0.00027811268739869055)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.037966442108154294), np.float64(-0.0007542914079353147)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.04362330436706543), np.float64(-2.220446049250313e-16)], [np.float64(-0.07625924348831177), np.float64(-0.009974250462321088)], [np.float64(-0.06490075349807739), np.float64(-0.003130830814211061)], [np.float64(-0.03988151550292969), np.float64(-2.7755575615628914e-16)], [np.float64(-0.05448806285858154), np.float64(-0.003909707145245467)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.06254790306091308), np.float64(-0.004783720618306508)], [np.float64(-0.06511961698532104), np.float64(-0.008264568081113643)], [np.float64(-0.04303146362304688), np.float64(-0.0008571846634832236)], [np.float64(-0.23480236530303955), np.float64(-1.9668616997824362)], [np.float64(-0.04586038589477539), np.float64(-1.6653345369377348e-16)], [np.float64(-0.2781452751159668), np.float64(-1.7888543819998324)], [np.float64(-0.04136776924133301), np.float64(-2.7755575615628914e-16)], [np.float64(-0.04903143167495728), np.float64(-0.004932187194581272)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.0545225715637207), np.float64(-0.0075293605112413675)]]], 'normalized_truth_values': [[[np.float64(0.48894752329466645), np.float64(0.5)], [np.float64(0.4889795630548023), np.float64(0.49999999999999994)], [np.float64(0.48988758315025166), np.float64(0.4998483115021486)], [np.float64(0.489937305363533), np.float64(0.49999999999999983)], [np.float64(0.48975829108220026), np.float64(0.49999999999999994)], [np.int64(0), np.int64(0)], [np.float64(0.46122468634719194), np.float64(0.11812848236904606)], [np.float64(0.49021138046212587), np.float64(0.49993047182859846)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.4905095294493805), np.float64(0.499811427156957)], [np.int64(0), np.int64(0)], [np.float64(0.4890959030547844), np.float64(0.49999999999999994)], [np.float64(0.4809444229978576), np.float64(0.4975064580570268)], [np.float64(0.4837805044145106), np.float64(0.499217292935795)], [np.float64(0.4900309424340544), np.float64(0.49999999999999994)], [np.float64(0.4863813535408645), np.float64(0.4990225744587501)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.48436812020818387), np.float64(0.49880407212605526)], [np.float64(0.4837258463138096), np.float64(0.4979338697399642)], [np.float64(0.4892437938214156), np.float64(0.49978570384725063)], [np.float64(0.4415676208805046), np.float64(0.12272637083071242)], [np.float64(0.4885369125291298), np.float64(0.49999999999999994)], [np.float64(0.4309085451059894), np.float64(0.14321323703222505)], [np.float64(0.48965953227786996), np.float64(0.49999999999999994)], [np.float64(0.4877445972315996), np.float64(0.4987669557009883)], [np.int64(0), np.int64(0)], [np.float64(0.4863727327688763), np.float64(0.49811766876482694)]]]}}}