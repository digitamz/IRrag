{'sample_level_eval_list': {'claim_check_methods_0_truth_method_0': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}, 'claim_check_methods_0_truth_method_1': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}}, 'dataset_level_eval_list': {'claim_check_methods_0_truth_method_0': {'prr': np.float64(0.23580559019422534)}, 'claim_check_methods_0_truth_method_1': {'prr': np.float64(0.18669555756727452)}}, 'output_dict': {'previous_context': [{'role': 'system', 'content': 'You are a helpful assistant. Give precise answers.'}], 'user_prompt': 'Context: {context}\nQuestion: {question}', 'generation': ['Stephanus Andries Johannes Swart (1890 – 6 May 1927) was a South African farmer who gained notoriety for a spree killing that took place on 6 May 1927 in Charlestown, South Africa. Here is a detailed biography:\n\n### Early Life\n- **Birth and Background**: Born in 1890, Stephanus Swart was a farmer in the Charlestown area of South Africa.\n- **Personal Life**: Swart lived and worked on his farm, where he was known to the local community.\n\n### Pre-incident Behavior\n- **Initial Incident**: On 3 May 1927, Swart fired a shot at his neighbor, Mr. Lourens, for no apparent reason. This act of aggression did not result in immediate consequences but set the stage for his later actions.\n- **Police Investigation**: After the incident with Lourens, the police began to investigate Swart, though they did not immediately apprehend him.\n\n### The Spree Killing\n- **Suicide Note**: On 6 May 1927, Swart summoned his attorney and dictated a 28-page suicide statement. During this time, he set his car on fire and hiked 10 miles to his farmhouse.\n- **First Victims**: Swart then proceeded to Charlestown, where he killed at least eight people and wounded three others. His victims included individuals who had testified against him in a previous crime (incest) for which he had been convicted and sentenced to several months in prison.\n- **Threats and Escalation**: Swart told a nearby neighbor that he intended to kill three more people in Charlestown before heading to Volkrust to commit suicide. This neighbor warned the police, but Swart had already moved on.\n- **Additional Victims**: While on the road, Swart encountered and killed two more people. He also left a note with a black person, threatening to return and kill his neighbor, Swanepoel, after completing his "mission."\n\n### Final Acts\n- **Suicide**: After his spree of killings, Stephanus Swart took his own life on 6 May 1927.\n- **Aftermath**: The incident shocked the local community and highlighted issues of mental health and rural crime in early 20th-century South Africa.\n\n### Legacy\n- **Notoriety**: Stephanus Swart is remembered as one of the first spree killers in South African history, and his actions have been studied in the context of criminal psychology and the social conditions of the time.\n\nThis biography provides a comprehensive overview of the life and tragic actions of Stephanus Andries Johannes Swart.'], 'claims': [['Stephanus Andries Johannes Swart was born in 1890.', 'Stephanus Andries Johannes Swart died on 6 May 1927.', 'Stephanus Andries Johannes Swart was a South African farmer.', 'Stephanus Andries Johannes Swart gained notoriety for a spree killing.', 'The spree killing took place on 6 May 1927.', 'The spree killing took place in Charlestown, South Africa.', 'Stephanus Swart was born in 1890.', 'Stephanus Swart was a farmer.', 'Stephanus Swart lived in the Charlestown area of South Africa.', 'Swart lived and worked on his farm.', 'Swart was known to the local community.', 'On 3 May 1927, Swart fired a shot at his neighbor, Mr. Lourens, for no apparent reason.', 'This act of aggression did not result in immediate consequences.', "This act of aggression set the stage for Swart's later actions.", 'After the incident with Lourens, the police began to investigate Swart.', 'The police did not immediately apprehend Swart.', 'On 6 May 1927, Swart summoned his attorney and dictated a 28-page suicide statement.', 'Swart set his car on fire on 6 May 1927.', 'Swart hiked 10 miles to his farmhouse on 6 May 1927.', 'Swart killed at least eight people in Charlestown.', 'Swart wounded three others in Charlestown.', "Some of Swart's victims had testified against him in a previous crime.", 'Swart was convicted of incest.', 'Swart was sentenced to several months in prison for incest.', 'Swart told a nearby neighbor that he intended to kill three more people in Charlestown.', 'Swart intended to head to Volkrust to commit suicide after killing three more people.', "This neighbor warned the police about Swart's intentions.", 'Swart had already moved on by the time the police were warned.', 'Swart encountered and killed two more people while on the road.', 'Swart left a note with a black person.', "Swart threatened to return and kill his neighbor, Swanepoel, after completing his 'mission.'", 'Stephanus Swart took his own life on 6 May 1927.', 'The incident shocked the local community.', 'The incident highlighted issues of mental health in early 20th-century South Africa.', 'The incident highlighted issues of rural crime in early 20th-century South Africa.', 'Stephanus Swart is remembered as one of the first spree killers in South African history.', "Stephanus Swart's actions have been studied in the context of criminal psychology.", "Stephanus Swart's actions have been studied in the context of the social conditions of the time.", 'This biography provides a comprehensive overview of the life and tragic actions of Stephanus Andries Johannes Swart.']], 'claim_correctness': [array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1])], 'question_text': ['Tell me a bio of Stephanus Swart.'], 'context': ['{\n  "id" : "7158482",\n  "contents" : "\\"Balie Swart\\"\\nBalie Swart Izak Stephanus de Villiers Swart (born Malmesbury, 18 May 1964), known as Balie Swart, is a former South African rugby union footballer. He played as a prop (1.85 m, 112 kg), with the ability to prop on either side of the hooker. He played for Transvaal, now Golden Lions, until 1999. He had 16 caps for South Africa, from 1993 to 1996, never scoring. He was a member of the winning team at the 1995 World Cup finals, where he played in four games, including the 15-12 win at the final with the All Blacks. Together with Os"\n}\n{\n  "id" : "15982683",\n  "contents" : "\\"Stephanus Swart\\"\\nStephanus Swart Stephanus Andries Johannes Swart (1890 – 6 May 1927) was a South African farmer and one of the first spree killers who killed at least 8 people and wounded 3 others in Charlestown, South Africa on 6 May 1927, before killing himself. Police pursued Swart one day after he fired a shot at his neighbour, Mr Lourens, on 3 May 1927 for no apparent reason. At some point Swart summoned his attorney and ordered him to write down Swart\'s 28-page suicide statement after setting his own car on fire and hiking 10 miles to his farm house. Swart"\n}\n{\n  "id" : "15982685",\n  "contents" : "\\"Stephanus Swart\\"\\nto a nearby house to tell his neighbour that he intended to go into Charlestown to kill three more people before going to Volkrust to kill himself. The neighbour departed to warn police of Swart\'s coming. His neighbour, Swanepoel, when nearing Mount Prospect, was approached by a black person with a note from Swart saying he would return to kill him after he completed his \\"\\"mission\\"\\". By now Swart had killed two more people on the road, who had testified against him in a previous crime (incest) for which he had been convicted and sentenced to several months in prison."\n}'], 'claim_check_methods': ['QuestionAnswerGeneration'], 'claim_check_methods_0': {'name': 'Claim Check Method by Generating Questions and Answers.\nQuestion generation model: openrouter/qwen/qwen-2.5-72b-instruct\nNumber of questions to be generated for a stament: 2\nNumber of trials to generate an answer that entails with the claim: 2\nEntailment check model: <class \'transformers.models.deberta.modeling_deberta.DebertaForSequenceClassification\'>\n\nQuestion generation instruction for the first claim:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nQuestion generation instruction for claims with preceeding text:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nAnswer generation instruction:\n    [{\'role\': \'system\', \'content\': \'You are a helpful assistant. Give a single claim answer to given question. Don\\\\‘t provide any additional information. Just answer the question with a brief sentence in a single claim.\'}, {\'role\': \'user\', \'content\': \'{question}\'}]\n\nTruth methods to assign a score the question(s):\n   [<TruthTorchLM.truth_methods.matrix_degree_uncertainty.MatrixDegreeUncertainty object at 0x000001A81BBC4BB0>, <TruthTorchLM.truth_methods.eccentricity_uncertainty.EccentricityUncertainty object at 0x000001A81BDD9450>]', 'truth_methods': ['MatrixDegreeUncertainty', 'EccentricityUncertainty'], 'truth_methods_name': ['MatrixDegreeUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x000001A81BD7FFA0>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'temperature\': 3.0, \'batch_generation\': True}', 'EccentricityUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x000001A81BDEA6E0>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'eigen_threshold\': 0.9, \'temperature\': 3.0, \'batch_generation\': True}'], 'truth_values': [[[np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.5379532361030579), np.float64(-3.7790344619090193)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.03844156265258789), np.float64(-3.3306690738754696e-16)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.5863764905929565), np.float64(-3.08531742102058)], [np.float64(-0.13150850296020508), np.float64(-1.8443732348835544)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.043709025382995606), np.float64(-0.001997332326755197)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.0494994044303894), np.float64(-0.0030040266896181334)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.09604175806045533), np.float64(-0.03734437047005812)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.051482987403869626), np.float64(-0.0049639863778784266)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.04950823783874512), np.float64(-1.6653345369377348e-16)], [np.float64(-0.35326590538024905), np.float64(-2.1055424166126873)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.26058327198028564), np.float64(-1.7859872920510145)], [np.float64(-0.26380339860916135), np.float64(-1.9747558273980983)], [np.float64(-0.4141796875), np.float64(-2.1908902300206647)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.03906269073486328), np.float64(-2.7755575615628914e-16)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.03681960105895996), np.float64(-1.1102230246251565e-16)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.09974495887756347), np.float64(-0.03554036373563835)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.08491801023483277), np.float64(-0.02339352776867043)], [np.float64(-0.13193151473999024), np.float64(-1.7543848705904996)], [np.float64(-10000000000.0), np.float64(-10000000000.0)]]], 'normalized_truth_values': [[[np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.3686638400340333), np.float64(0.02233451216067572)], [np.int64(0), np.int64(0)], [np.float64(0.49039079264455104), np.float64(0.49999999999999994)], [np.int64(0), np.int64(0)], [np.float64(0.35746668683556626), np.float64(0.04371697620646814)], [np.float64(0.46717017520727105), np.float64(0.13653489827613502)], [np.int64(0), np.int64(0)], [np.float64(0.48907448301300793), np.float64(0.49950066708431173)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.48762767500256693), np.float64(0.499248993892363)], [np.int64(0), np.int64(0)], [np.float64(0.4760079995399597), np.float64(0.4906649922423152)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.4871320952198017), np.float64(0.49875900595382383)], [np.int64(0), np.int64(0)], [np.float64(0.48762546800288814), np.float64(0.49999999999999994)], [np.float64(0.41259067221304546), np.float64(0.10855929360453187)], [np.int64(0), np.int64(0)], [np.float64(0.4352203324342776), np.float64(0.1435653981585541)], [np.float64(0.4344289794926367), np.float64(0.121878980806359)], [np.float64(0.3979103352256739), np.float64(0.10057153747411847)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.4902355689084535), np.float64(0.49999999999999994)], [np.int64(0), np.int64(0)], [np.float64(0.49079613950488454), np.float64(0.49999999999999994)], [np.int64(0), np.int64(0)], [np.float64(0.4750844140711025), np.float64(0.49111584419076026)], [np.int64(0), np.int64(0)], [np.float64(0.4787832455316663), np.float64(0.49415188475730243)], [np.float64(0.4670648796471714), np.float64(0.14749499078982833)], [np.int64(0), np.int64(0)]]]}}}