{'sample_level_eval_list': {'claim_check_methods_0_truth_method_0': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}, 'claim_check_methods_0_truth_method_1': {'f1': {'values': [0.0], 'mean': np.float64(0.0), 'max': np.float64(0.0), 'min': np.float64(0.0), 'std': np.float64(0.0)}}}, 'dataset_level_eval_list': {'claim_check_methods_0_truth_method_0': {'prr': np.float64(0.5)}, 'claim_check_methods_0_truth_method_1': {'prr': np.float64(0.5)}}, 'output_dict': {'previous_context': [{'role': 'system', 'content': 'You are a helpful assistant. Give precise answers.'}], 'user_prompt': 'Context: {context}\nQuestion: {question}', 'generation': ['Umika Kawashima is a Japanese actress, voice actress, and former idol born in Saitama Prefecture. She was discovered and scouted in Shibuya while in 6th grade and subsequently joined Lespros Entertainment. Umika has expressed admiration for actresses Aoi Miyazaki, Yui Aragaki, and Kou Shibasaki, and has expressed a desire to collaborate with Masaharu Fukuyama.\n\nKawashima graduated from the Faculty of Arts and Letters at Meiji University in 2016 with a degree in psychology. Her acting career began in 2006, and since then, she has appeared in numerous television dramas and movies. In 2007, she joined the female idol group 9nine, where she remained for nine and a half years until her graduation from the group in 2016 to focus on her acting career. Her final performance with 9nine was during the "9nine LIVE 2016, BEST 9 Tour."\n\nIn early 2016, Kawashima became a regular cast member on the morning television program ZIP!, alongside Masu Taichi. She commented on this new role, stating, "Now is the time to move forward. I want to present an exciting program without any accidents."\n\nUmika received her first leading role as a voice actress in the 2017 summer anime series, "Nana Maru San Batsu."'], 'claims': [['Umika Kawashima is a Japanese actress, voice actress, and former idol.', 'Umika Kawashima was born in Saitama Prefecture.', 'Umika Kawashima was discovered and scouted in Shibuya while in 6th grade.', 'Umika Kawashima joined Lespros Entertainment.', 'Umika Kawashima has expressed admiration for actress Aoi Miyazaki.', 'Umika Kawashima has expressed admiration for actress Yui Aragaki.', 'Umika Kawashima has expressed admiration for actress Kou Shibasaki.', 'Umika Kawashima has expressed a desire to collaborate with Masaharu Fukuyama.', 'Kawashima graduated from the Faculty of Arts and Letters at Meiji University in 2016 with a degree in psychology.', "Kawashima's acting career began in 2006.", 'Kawashima has appeared in numerous television dramas and movies.', 'Kawashima joined the female idol group 9nine in 2007.', 'Kawashima remained in the female idol group 9nine for nine and a half years.', 'Kawashima graduated from the female idol group 9nine in 2016 to focus on her acting career.', "Kawashima's final performance with 9nine was during the '9nine LIVE 2016, BEST 9 Tour.'", 'In early 2016, Kawashima became a regular cast member on the morning television program ZIP!', 'Kawashima became a regular cast member on ZIP! alongside Masu Taichi.', "Kawashima commented on her new role, stating, 'Now is the time to move forward. I want to present an exciting program without any accidents.'", "Umika received her first leading role as a voice actress in the 2017 summer anime series, 'Nana Maru San Batsu.'"]], 'claim_correctness': [array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])], 'question_text': ['Tell me a bio of Umika Kawashima.'], 'context': ['{\n  "id" : "15061464",\n  "contents" : "\\"Umika Kawashima\\"\\nUmika Kawashima Umika Kawashima was born in the Saitama Prefecture. She was scouted in Shibuya when she was in 6th grade and joined Lespros Entertainment. The actresses she idolizes are Aoi Miyazaki, Yui Aragaki and Kou Shibasaki. She has stated that she would like to collaborate with Masaharu Fukuyama. She graduated from the Faculty of Arts and Letters at Meiji University with a degree in psychology in 2016. Since 2006, Kawashima has appeared in numerous television dramas and movies. In 2007 she joined the female idol group 9nine, however she announced her graduation from the group in 2016 to focus"\n}\n{\n  "id" : "15061465",\n  "contents" : "\\"Umika Kawashima\\"\\non her acting career. She appeared for her final performance with the group during \\"\\"9nine LIVE 2016,\\"\\" BEST 9 Tour\\"\\" after being with the group for nine and a half years. Early 2016, it was announced that Kawashima would become a regular alongside Masu Taichi on the television program ZIP!. Kawashima commented, \\"\\"Now is the time to move forward. I want to present an exciting program without any accidents.\\"\\" She receives her first leading role as a voice actress in the 2017 summer anime series, Nana Maru San Batsu. Umika Kawashima Umika Kawashima was born in the Saitama Prefecture. She"\n}\n{\n  "id" : "16265617",\n  "contents" : "\\"Ryuta Kawashima\\"\\nRyuta Kawashima Kawashima was born May 23, 1959 in Chiba City, Chiba Prefecture, Japan. In the 1970s, he enrolled in Tohoku University. After graduating with an M.D. at the school of medicine, he emigrated to Sweden to become a guest researcher at the Karolinska Institutet. He moved back to Tohoku and is now a resident Professor with tenure. He is famous in Japan and is a former member of Japan\'s National Council, concerning Language and Culture. One of his primary research topics is mapping the regions of the brain to faculties such as emotion, language, memorization, and cognition. Kawashima is"\n}'], 'claim_check_methods': ['QuestionAnswerGeneration'], 'claim_check_methods_0': {'name': 'Claim Check Method by Generating Questions and Answers.\nQuestion generation model: openrouter/qwen/qwen-2.5-72b-instruct\nNumber of questions to be generated for a stament: 2\nNumber of trials to generate an answer that entails with the claim: 2\nEntailment check model: <class \'transformers.models.deberta.modeling_deberta.DebertaForSequenceClassification\'>\n\nQuestion generation instruction for the first claim:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nQuestion generation instruction for claims with preceeding text:\n  [{\'role\': \'system\', \'content\': "You are an expert assistant skilled at generating focused and contextually relevant questions from claims. Your task is to create a question such that the answer would align closely with the provided claim. To ensure the question is precise and relevant, consider the context provided by the original question. Study the examples below from a variety of topics and follow the same pattern.\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 explores the theme of government surveillance. \\nQuestion: What theme does George Orwell\'s novel 1984 explore?   \\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: George Orwell\'s novel 1984 portrays a totalitarian regime that monitors every aspect of citizens\' lives. \\nQuestion: How does George Orwell\'s novel 1984 reflect the theme of totalitarian control, as commonly explored in 20th-century dystopian literature?\\n\\nOriginal Question: What themes are commonly explored in 20th-century dystopian literature?\\nClaim: The novel 1984 is written by George Orwell.\\nQuestion: Who has written the novel 1984?\\n\\nOriginal Question: How has artificial intelligence influenced industries in the 21st century?\\nClaim: Artificial intelligence enables better decision-making through data analysis.\\nQuestion: How does artificial intelligence enhance the decision-making process in modern businesses?\\n\\nOriginal Question: What factors contributed to the Great Depression, and how did governments respond?\\nClaim: Stock market speculation contributed to the Great Depression.\\nQuestion: Did stock market speculation contribute to the Great Depression?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln is best known for leading the country through the Civil War.\\nQuestion: What is Abraham Lincoln\'s most significant historical contribution?\\n\\nOriginal Question: Who is Abraham Lincoln?\\nClaim: Abraham Lincoln served from 1861 to 1865 as the president of the US.\\nQuestion: When did Abraham Lincoln serve as the president of the United States?\\n\\nNow, follow the pattern demonstrated in the examples to generate a question for the given claim,without adding explanations, introductions, or conversational responses."}, {\'role\': \'user\', \'content\': \'Original question: {question}\\nClaim: {claim}\\nQuestion: \'}]\n\nAnswer generation instruction:\n    [{\'role\': \'system\', \'content\': \'You are a helpful assistant. Give a single claim answer to given question. Don\\\\â€˜t provide any additional information. Just answer the question with a brief sentence in a single claim.\'}, {\'role\': \'user\', \'content\': \'{question}\'}]\n\nTruth methods to assign a score the question(s):\n   [<TruthTorchLM.truth_methods.matrix_degree_uncertainty.MatrixDegreeUncertainty object at 0x000001873EA04BE0>, <TruthTorchLM.truth_methods.eccentricity_uncertainty.EccentricityUncertainty object at 0x000001873EC19480>]', 'truth_methods': ['MatrixDegreeUncertainty', 'EccentricityUncertainty'], 'truth_methods_name': ['MatrixDegreeUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x000001873EBBFF10>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'temperature\': 3.0, \'batch_generation\': True}', 'EccentricityUncertainty with {\'normalizer\': <TruthTorchLM.normalizers.sigmoid_normalizer.SigmoidNormalizer object at 0x000001873EC2A6B0>, \'model_for_entailment\': DebertaForSequenceClassification(\n  (deberta): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 1024)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n), \'tokenizer_for_entailment\': DebertaTokenizer(name_or_path=\'microsoft/deberta-large-mnli\', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side=\'right\', truncation_side=\'right\', special_tokens={\'bos_token\': \'[CLS]\', \'eos_token\': \'[SEP]\', \'unk_token\': \'[UNK]\', \'sep_token\': \'[SEP]\', \'pad_token\': \'[PAD]\', \'cls_token\': \'[CLS]\', \'mask_token\': \'[MASK]\'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t50264: AddedToken("[MASK]", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n), \'number_of_generations\': 5, \'method_for_similarity\': \'semantic\', \'eigen_threshold\': 0.9, \'temperature\': 3.0, \'batch_generation\': True}'], 'truth_values': [[[np.float64(-0.2295037817955017), np.float64(-1.7713097043601953)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.11175384759902954), np.float64(-1.455865353889703)], [np.float64(-0.4348441982269287), np.float64(-3.586590028316872)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.49672914505004884), np.float64(-2.8842994970101645)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.06483025312423706), np.float64(-0.0065671523464958526)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.28801483154296875), np.float64(-1.7888543819998317)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-0.2540962529182434), np.float64(-2.571601116117139)], [np.float64(-0.4178463959693909), np.float64(-3.5855115976649277)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)], [np.float64(-10000000000.0), np.float64(-10000000000.0)]]], 'normalized_truth_values': [[[np.float64(0.44287457716374223), np.float64(0.14537953001800177)], [np.int64(0), np.int64(0)], [np.float64(0.4720905786059966), np.float64(0.18910052326147936)], [np.float64(0.3929701769827606), np.float64(0.02694638510643961)], [np.int64(0), np.int64(0)], [np.float64(0.3783096391764433), np.float64(0.05293517475492411)], [np.int64(0), np.int64(0)], [np.float64(0.48379811098141917), np.float64(0.4983582178138672)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.float64(0.4284899384867464), np.float64(0.14321323703222513)], [np.int64(0), np.int64(0)], [np.float64(0.43681552978931165), np.float64(0.07098863911524818)], [np.float64(0.397032203340369), np.float64(0.02697467628748944)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)], [np.int64(0), np.int64(0)]]]}}}